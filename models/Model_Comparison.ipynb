{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "64ba101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "import optuna\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import open_clip\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2914500",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33179ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>income</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>risk_preference</th>\n",
       "      <th>preference_1</th>\n",
       "      <th>preference_2</th>\n",
       "      <th>preference_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>female</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>medium</td>\n",
       "      <td>divorced</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>male</td>\n",
       "      <td>master</td>\n",
       "      <td>medium</td>\n",
       "      <td>single</td>\n",
       "      <td>0.18</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>female</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>medium</td>\n",
       "      <td>married</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>female</td>\n",
       "      <td>master</td>\n",
       "      <td>medium</td>\n",
       "      <td>married</td>\n",
       "      <td>0.39</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>male</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>medium</td>\n",
       "      <td>single</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>high school</td>\n",
       "      <td>high</td>\n",
       "      <td>single</td>\n",
       "      <td>0.04</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>76</td>\n",
       "      <td>male</td>\n",
       "      <td>master</td>\n",
       "      <td>medium</td>\n",
       "      <td>single</td>\n",
       "      <td>0.12</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>39</td>\n",
       "      <td>male</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>high</td>\n",
       "      <td>single</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>35</td>\n",
       "      <td>male</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>high</td>\n",
       "      <td>married</td>\n",
       "      <td>0.27</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>high school</td>\n",
       "      <td>high</td>\n",
       "      <td>married</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9992 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  gender    education  income marital_status  risk_preference  \\\n",
       "0      49  female     bachelor  medium       divorced            -0.70   \n",
       "1      61    male       master  medium         single             0.18   \n",
       "2      41  female     bachelor  medium        married            -0.32   \n",
       "3      45  female       master  medium        married             0.39   \n",
       "4      64    male     bachelor  medium         single            -0.71   \n",
       "...   ...     ...          ...     ...            ...              ...   \n",
       "9987   31  female  high school    high         single             0.04   \n",
       "9988   76    male       master  medium         single             0.12   \n",
       "9989   39    male     bachelor    high         single            -0.14   \n",
       "9990   35    male     bachelor    high        married             0.27   \n",
       "9991   33    male  high school    high        married            -0.08   \n",
       "\n",
       "      preference_1  preference_2  preference_3  \n",
       "0               13             6             8  \n",
       "1                6             8            13  \n",
       "2                6            13             8  \n",
       "3                6             9            13  \n",
       "4                8             6            13  \n",
       "...            ...           ...           ...  \n",
       "9987             6             8            13  \n",
       "9988             6            13             8  \n",
       "9989             6             8            14  \n",
       "9990            10             6            13  \n",
       "9991            10             8            13  \n",
       "\n",
       "[9992 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles = pd.read_csv('../data/profiles_presampled.csv')\n",
    "\n",
    "def is_valid_row(row):\n",
    "    try:\n",
    "        int(row['preference_1'])\n",
    "        int(row['preference_2'])\n",
    "        int(row['preference_3'])\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "profiles = profiles[profiles.apply(is_valid_row, axis=1)].reset_index(drop=True)\n",
    "preference_cols = ['preference_1', 'preference_2', 'preference_3']\n",
    "\n",
    "for col in preference_cols:\n",
    "    profiles[col] = pd.to_numeric(profiles[col], errors='coerce').astype('Int64')\n",
    "\n",
    "profiles = profiles[\n",
    "    profiles[preference_cols].apply(lambda x: x.between(1, 17)).all(axis=1)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f34c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, categorical_cols, features, target, test_size=0.2, random_state=42):\n",
    "    df = df.copy()\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_train\n",
    "\n",
    "    start_infer = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    inference_time = time.time() - start_infer\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{model_name}: MSE={mse:.4f}, R2={r2:.4f}, train_time={train_time:.4f}s, inference_time={inference_time:.4f}s\")\n",
    "\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'mse': mse,\n",
    "        'r2': r2,\n",
    "        'train_time': train_time,\n",
    "        'inference_time': inference_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "646faa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['gender', 'education', 'income', 'marital_status']\n",
    "target = 'risk_preference'\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d62ca9",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6d85951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 0.2395\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(profiles.drop(columns=[target]), profiles[target], test_size=0.2, random_state=42)\n",
    "\n",
    "start_train = time.time()\n",
    "baseline_pred = np.ones_like(y_test) * y_train.mean()\n",
    "train_time = time.time() - start_train\n",
    "\n",
    "baseline_mse = mean_squared_error(y_test, baseline_pred)\n",
    "\n",
    "results.append({\n",
    "    'model': 'Baseline (mean prediction)',\n",
    "    'mse': baseline_mse,\n",
    "    'r2': 0,\n",
    "    'train_time': train_time,\n",
    "    'inference_time': 0\n",
    "})\n",
    "\n",
    "print(f\"Baseline MSE: {baseline_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f75421e",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1635fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_rf_with_optuna(X_train, y_train, n_trials=50, random_state=42):\n",
    "    def objective(trial):\n",
    "        n_estimators = trial.suggest_int('n_estimators', 20, 300)\n",
    "        max_depth = trial.suggest_int('max_depth', 2, 5)\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 15, 60)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 10, 30)\n",
    "\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=random_state\n",
    "        )\n",
    "\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "        mse = -np.mean(scores)\n",
    "        return mse\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    print(\"Best params:\", study.best_params)\n",
    "    print(\"Best CV MSE:\", study.best_value)\n",
    "\n",
    "    return study.best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d84f8b3",
   "metadata": {},
   "source": [
    "## RF: only socio-demographic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8178ddca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 23:14:59,407] A new study created in memory with name: no-name-6a5c234a-5839-4ace-b417-57644dca09c0\n",
      "[I 2025-06-21 23:14:59,584] Trial 0 finished with value: 0.23007781868665086 and parameters: {'n_estimators': 28, 'max_depth': 2, 'min_samples_split': 51, 'min_samples_leaf': 21}. Best is trial 0 with value: 0.23007781868665086.\n",
      "[I 2025-06-21 23:15:00,643] Trial 1 finished with value: 0.22997527227577078 and parameters: {'n_estimators': 188, 'max_depth': 2, 'min_samples_split': 47, 'min_samples_leaf': 12}. Best is trial 1 with value: 0.22997527227577078.\n",
      "[I 2025-06-21 23:15:02,750] Trial 2 finished with value: 0.23003208843086012 and parameters: {'n_estimators': 270, 'max_depth': 3, 'min_samples_split': 38, 'min_samples_leaf': 11}. Best is trial 1 with value: 0.22997527227577078.\n",
      "[I 2025-06-21 23:15:03,875] Trial 3 finished with value: 0.23023146732772498 and parameters: {'n_estimators': 124, 'max_depth': 4, 'min_samples_split': 48, 'min_samples_leaf': 20}. Best is trial 1 with value: 0.22997527227577078.\n",
      "[I 2025-06-21 23:15:05,393] Trial 4 finished with value: 0.2304451460542199 and parameters: {'n_estimators': 114, 'max_depth': 5, 'min_samples_split': 18, 'min_samples_leaf': 30}. Best is trial 1 with value: 0.22997527227577078.\n",
      "[I 2025-06-21 23:15:05,649] Trial 5 finished with value: 0.23010428028786625 and parameters: {'n_estimators': 35, 'max_depth': 3, 'min_samples_split': 19, 'min_samples_leaf': 19}. Best is trial 1 with value: 0.22997527227577078.\n",
      "[I 2025-06-21 23:15:07,380] Trial 6 finished with value: 0.23003683171930228 and parameters: {'n_estimators': 225, 'max_depth': 3, 'min_samples_split': 19, 'min_samples_leaf': 13}. Best is trial 1 with value: 0.22997527227577078.\n",
      "[I 2025-06-21 23:15:09,090] Trial 7 finished with value: 0.23044309738065955 and parameters: {'n_estimators': 180, 'max_depth': 5, 'min_samples_split': 25, 'min_samples_leaf': 27}. Best is trial 1 with value: 0.22997527227577078.\n",
      "[I 2025-06-21 23:15:10,458] Trial 8 finished with value: 0.2302584720284712 and parameters: {'n_estimators': 136, 'max_depth': 4, 'min_samples_split': 37, 'min_samples_leaf': 14}. Best is trial 1 with value: 0.22997527227577078.\n",
      "[I 2025-06-21 23:15:12,412] Trial 9 finished with value: 0.23002262970809245 and parameters: {'n_estimators': 257, 'max_depth': 3, 'min_samples_split': 59, 'min_samples_leaf': 22}. Best is trial 1 with value: 0.22997527227577078.\n",
      "[I 2025-06-21 23:15:13,582] Trial 10 finished with value: 0.22997223212385925 and parameters: {'n_estimators': 190, 'max_depth': 2, 'min_samples_split': 34, 'min_samples_leaf': 16}. Best is trial 10 with value: 0.22997223212385925.\n",
      "[I 2025-06-21 23:15:14,802] Trial 11 finished with value: 0.22997494130585996 and parameters: {'n_estimators': 197, 'max_depth': 2, 'min_samples_split': 36, 'min_samples_leaf': 16}. Best is trial 10 with value: 0.22997223212385925.\n",
      "[I 2025-06-21 23:15:16,161] Trial 12 finished with value: 0.22997225116866918 and parameters: {'n_estimators': 212, 'max_depth': 2, 'min_samples_split': 33, 'min_samples_leaf': 16}. Best is trial 10 with value: 0.22997223212385925.\n",
      "[I 2025-06-21 23:15:17,329] Trial 13 finished with value: 0.22996766370429222 and parameters: {'n_estimators': 231, 'max_depth': 2, 'min_samples_split': 30, 'min_samples_leaf': 17}. Best is trial 13 with value: 0.22996766370429222.\n",
      "[I 2025-06-21 23:15:19,078] Trial 14 finished with value: 0.22996318370437147 and parameters: {'n_estimators': 300, 'max_depth': 2, 'min_samples_split': 29, 'min_samples_leaf': 17}. Best is trial 14 with value: 0.22996318370437147.\n",
      "[I 2025-06-21 23:15:20,554] Trial 15 finished with value: 0.2299513740185643 and parameters: {'n_estimators': 295, 'max_depth': 2, 'min_samples_split': 27, 'min_samples_leaf': 25}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:22,900] Trial 16 finished with value: 0.2302017276827919 and parameters: {'n_estimators': 300, 'max_depth': 4, 'min_samples_split': 26, 'min_samples_leaf': 24}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:24,943] Trial 17 finished with value: 0.23001627788976148 and parameters: {'n_estimators': 294, 'max_depth': 3, 'min_samples_split': 26, 'min_samples_leaf': 26}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:26,308] Trial 18 finished with value: 0.2299532446405479 and parameters: {'n_estimators': 253, 'max_depth': 2, 'min_samples_split': 44, 'min_samples_leaf': 24}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:27,929] Trial 19 finished with value: 0.23001461375047091 and parameters: {'n_estimators': 250, 'max_depth': 3, 'min_samples_split': 43, 'min_samples_leaf': 29}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:28,304] Trial 20 finished with value: 0.230005247251427 and parameters: {'n_estimators': 68, 'max_depth': 2, 'min_samples_split': 56, 'min_samples_leaf': 24}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:29,858] Trial 21 finished with value: 0.2299559367241304 and parameters: {'n_estimators': 276, 'max_depth': 2, 'min_samples_split': 42, 'min_samples_leaf': 23}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:31,455] Trial 22 finished with value: 0.22995316820085526 and parameters: {'n_estimators': 272, 'max_depth': 2, 'min_samples_split': 42, 'min_samples_leaf': 24}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:33,225] Trial 23 finished with value: 0.22995445030538414 and parameters: {'n_estimators': 247, 'max_depth': 2, 'min_samples_split': 42, 'min_samples_leaf': 26}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:35,153] Trial 24 finished with value: 0.23001397149237784 and parameters: {'n_estimators': 275, 'max_depth': 3, 'min_samples_split': 51, 'min_samples_leaf': 28}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:36,045] Trial 25 finished with value: 0.22996887528074184 and parameters: {'n_estimators': 157, 'max_depth': 2, 'min_samples_split': 40, 'min_samples_leaf': 24}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:37,533] Trial 26 finished with value: 0.23001665963717327 and parameters: {'n_estimators': 227, 'max_depth': 3, 'min_samples_split': 45, 'min_samples_leaf': 26}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:38,972] Trial 27 finished with value: 0.22995759267937815 and parameters: {'n_estimators': 275, 'max_depth': 2, 'min_samples_split': 54, 'min_samples_leaf': 22}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:41,009] Trial 28 finished with value: 0.23020151906375075 and parameters: {'n_estimators': 255, 'max_depth': 4, 'min_samples_split': 33, 'min_samples_leaf': 25}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:42,132] Trial 29 finished with value: 0.22996314294909107 and parameters: {'n_estimators': 212, 'max_depth': 2, 'min_samples_split': 50, 'min_samples_leaf': 21}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:43,606] Trial 30 finished with value: 0.22996153991091822 and parameters: {'n_estimators': 285, 'max_depth': 2, 'min_samples_split': 15, 'min_samples_leaf': 19}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:44,896] Trial 31 finished with value: 0.2299590338736869 and parameters: {'n_estimators': 243, 'max_depth': 2, 'min_samples_split': 41, 'min_samples_leaf': 27}. Best is trial 15 with value: 0.2299513740185643.\n",
      "[I 2025-06-21 23:15:46,261] Trial 32 finished with value: 0.22994608073312423 and parameters: {'n_estimators': 264, 'max_depth': 2, 'min_samples_split': 45, 'min_samples_leaf': 25}. Best is trial 32 with value: 0.22994608073312423.\n",
      "[I 2025-06-21 23:15:47,826] Trial 33 finished with value: 0.22995329759917946 and parameters: {'n_estimators': 267, 'max_depth': 2, 'min_samples_split': 48, 'min_samples_leaf': 23}. Best is trial 32 with value: 0.22994608073312423.\n",
      "[I 2025-06-21 23:15:49,639] Trial 34 finished with value: 0.23001401214623232 and parameters: {'n_estimators': 285, 'max_depth': 3, 'min_samples_split': 45, 'min_samples_leaf': 28}. Best is trial 32 with value: 0.22994608073312423.\n",
      "[I 2025-06-21 23:15:51,023] Trial 35 finished with value: 0.22994579474138116 and parameters: {'n_estimators': 265, 'max_depth': 2, 'min_samples_split': 45, 'min_samples_leaf': 25}. Best is trial 35 with value: 0.22994579474138116.\n",
      "[I 2025-06-21 23:15:52,398] Trial 36 finished with value: 0.2299482690392149 and parameters: {'n_estimators': 265, 'max_depth': 2, 'min_samples_split': 38, 'min_samples_leaf': 30}. Best is trial 35 with value: 0.22994579474138116.\n",
      "[I 2025-06-21 23:15:53,025] Trial 37 finished with value: 0.23005728877699969 and parameters: {'n_estimators': 94, 'max_depth': 3, 'min_samples_split': 39, 'min_samples_leaf': 29}. Best is trial 35 with value: 0.22994579474138116.\n",
      "[I 2025-06-21 23:15:54,313] Trial 38 finished with value: 0.22995601130609006 and parameters: {'n_estimators': 235, 'max_depth': 2, 'min_samples_split': 22, 'min_samples_leaf': 30}. Best is trial 35 with value: 0.22994579474138116.\n",
      "[I 2025-06-21 23:15:55,924] Trial 39 finished with value: 0.23044967597364546 and parameters: {'n_estimators': 163, 'max_depth': 5, 'min_samples_split': 47, 'min_samples_leaf': 20}. Best is trial 35 with value: 0.22994579474138116.\n",
      "[I 2025-06-21 23:15:57,589] Trial 40 finished with value: 0.23002107292589558 and parameters: {'n_estimators': 210, 'max_depth': 3, 'min_samples_split': 36, 'min_samples_leaf': 28}. Best is trial 35 with value: 0.22994579474138116.\n",
      "[I 2025-06-21 23:15:59,003] Trial 41 finished with value: 0.22994915964834392 and parameters: {'n_estimators': 267, 'max_depth': 2, 'min_samples_split': 38, 'min_samples_leaf': 25}. Best is trial 35 with value: 0.22994579474138116.\n",
      "[I 2025-06-21 23:16:01,186] Trial 42 finished with value: 0.22995566578573481 and parameters: {'n_estimators': 288, 'max_depth': 2, 'min_samples_split': 38, 'min_samples_leaf': 26}. Best is trial 35 with value: 0.22994579474138116.\n",
      "[I 2025-06-21 23:16:02,857] Trial 43 finished with value: 0.22995169884195205 and parameters: {'n_estimators': 261, 'max_depth': 2, 'min_samples_split': 30, 'min_samples_leaf': 30}. Best is trial 35 with value: 0.22994579474138116.\n",
      "[I 2025-06-21 23:16:04,245] Trial 44 finished with value: 0.22997778860548176 and parameters: {'n_estimators': 267, 'max_depth': 2, 'min_samples_split': 35, 'min_samples_leaf': 10}. Best is trial 35 with value: 0.22994579474138116.\n",
      "[I 2025-06-21 23:16:05,474] Trial 45 finished with value: 0.2299599925062533 and parameters: {'n_estimators': 241, 'max_depth': 2, 'min_samples_split': 47, 'min_samples_leaf': 22}. Best is trial 35 with value: 0.22994579474138116.\n",
      "[I 2025-06-21 23:16:06,977] Trial 46 finished with value: 0.22995068450520856 and parameters: {'n_estimators': 289, 'max_depth': 2, 'min_samples_split': 51, 'min_samples_leaf': 25}. Best is trial 35 with value: 0.22994579474138116.\n",
      "[I 2025-06-21 23:16:08,379] Trial 47 finished with value: 0.23001654858988774 and parameters: {'n_estimators': 221, 'max_depth': 3, 'min_samples_split': 51, 'min_samples_leaf': 27}. Best is trial 35 with value: 0.22994579474138116.\n",
      "[I 2025-06-21 23:16:09,879] Trial 48 finished with value: 0.22995203304748113 and parameters: {'n_estimators': 281, 'max_depth': 2, 'min_samples_split': 53, 'min_samples_leaf': 25}. Best is trial 35 with value: 0.22994579474138116.\n",
      "[I 2025-06-21 23:16:10,013] Trial 49 finished with value: 0.2300857635694505 and parameters: {'n_estimators': 22, 'max_depth': 2, 'min_samples_split': 56, 'min_samples_leaf': 21}. Best is trial 35 with value: 0.22994579474138116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 265, 'max_depth': 2, 'min_samples_split': 45, 'min_samples_leaf': 25}\n",
      "Best CV MSE: 0.22994579474138116\n"
     ]
    }
   ],
   "source": [
    "features = ['age', 'gender', 'education', 'income', 'marital_status']\n",
    "X_train, X_test, y_train, y_test = preprocess_data(profiles, categorical_cols, features, target)\n",
    "\n",
    "best_params = optimize_rf_with_optuna(X_train, y_train, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cdd5c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest (socdem only): MSE=0.2397, R2=-0.0039, train_time=0.3062s, inference_time=0.0120s\n"
     ]
    }
   ],
   "source": [
    "best_rf = RandomForestRegressor(**best_params, random_state=42)\n",
    "results.append(train_and_evaluate(best_rf, \"RandomForest (socdem only)\", X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eb80aa",
   "metadata": {},
   "source": [
    "## RF: socdem fetures + weighted meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9313466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 23:16:14,704] A new study created in memory with name: no-name-72cbb6e4-c6e8-45b3-8194-bfb483bd6bcf\n",
      "[I 2025-06-21 23:16:15,151] Trial 0 finished with value: 0.22261351515311573 and parameters: {'n_estimators': 35, 'max_depth': 5, 'min_samples_split': 35, 'min_samples_leaf': 14}. Best is trial 0 with value: 0.22261351515311573.\n",
      "[I 2025-06-21 23:16:17,823] Trial 1 finished with value: 0.22336306333912354 and parameters: {'n_estimators': 221, 'max_depth': 3, 'min_samples_split': 25, 'min_samples_leaf': 18}. Best is trial 0 with value: 0.22261351515311573.\n",
      "[I 2025-06-21 23:16:19,223] Trial 2 finished with value: 0.22289376435328817 and parameters: {'n_estimators': 115, 'max_depth': 4, 'min_samples_split': 36, 'min_samples_leaf': 23}. Best is trial 0 with value: 0.22261351515311573.\n",
      "[I 2025-06-21 23:16:20,153] Trial 3 finished with value: 0.22250498101091756 and parameters: {'n_estimators': 75, 'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 30}. Best is trial 3 with value: 0.22250498101091756.\n",
      "[I 2025-06-21 23:16:23,050] Trial 4 finished with value: 0.22338521048201604 and parameters: {'n_estimators': 295, 'max_depth': 3, 'min_samples_split': 58, 'min_samples_leaf': 21}. Best is trial 3 with value: 0.22250498101091756.\n",
      "[I 2025-06-21 23:16:23,495] Trial 5 finished with value: 0.22342786963505135 and parameters: {'n_estimators': 51, 'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 14}. Best is trial 3 with value: 0.22250498101091756.\n",
      "[I 2025-06-21 23:16:25,831] Trial 6 finished with value: 0.22238792551481917 and parameters: {'n_estimators': 182, 'max_depth': 5, 'min_samples_split': 46, 'min_samples_leaf': 12}. Best is trial 6 with value: 0.22238792551481917.\n",
      "[I 2025-06-21 23:16:27,659] Trial 7 finished with value: 0.22420698902994873 and parameters: {'n_estimators': 277, 'max_depth': 2, 'min_samples_split': 15, 'min_samples_leaf': 27}. Best is trial 6 with value: 0.22238792551481917.\n",
      "[I 2025-06-21 23:16:28,689] Trial 8 finished with value: 0.22422367016803016 and parameters: {'n_estimators': 156, 'max_depth': 2, 'min_samples_split': 52, 'min_samples_leaf': 28}. Best is trial 6 with value: 0.22238792551481917.\n",
      "[I 2025-06-21 23:16:31,780] Trial 9 finished with value: 0.22282417144829725 and parameters: {'n_estimators': 285, 'max_depth': 4, 'min_samples_split': 37, 'min_samples_leaf': 19}. Best is trial 6 with value: 0.22238792551481917.\n",
      "[I 2025-06-21 23:16:34,173] Trial 10 finished with value: 0.22241176125309492 and parameters: {'n_estimators': 190, 'max_depth': 5, 'min_samples_split': 47, 'min_samples_leaf': 10}. Best is trial 6 with value: 0.22238792551481917.\n",
      "[I 2025-06-21 23:16:36,481] Trial 11 finished with value: 0.22239892171982065 and parameters: {'n_estimators': 185, 'max_depth': 5, 'min_samples_split': 47, 'min_samples_leaf': 10}. Best is trial 6 with value: 0.22238792551481917.\n",
      "[I 2025-06-21 23:16:38,981] Trial 12 finished with value: 0.22271208969294265 and parameters: {'n_estimators': 223, 'max_depth': 4, 'min_samples_split': 45, 'min_samples_leaf': 10}. Best is trial 6 with value: 0.22238792551481917.\n",
      "[I 2025-06-21 23:16:41,010] Trial 13 finished with value: 0.22248191751210525 and parameters: {'n_estimators': 149, 'max_depth': 5, 'min_samples_split': 45, 'min_samples_leaf': 14}. Best is trial 6 with value: 0.22238792551481917.\n",
      "[I 2025-06-21 23:16:43,575] Trial 14 finished with value: 0.22244130309266982 and parameters: {'n_estimators': 201, 'max_depth': 5, 'min_samples_split': 58, 'min_samples_leaf': 12}. Best is trial 6 with value: 0.22238792551481917.\n",
      "[I 2025-06-21 23:16:44,887] Trial 15 finished with value: 0.2228515488281741 and parameters: {'n_estimators': 112, 'max_depth': 4, 'min_samples_split': 50, 'min_samples_leaf': 16}. Best is trial 6 with value: 0.22238792551481917.\n",
      "[I 2025-06-21 23:16:48,082] Trial 16 finished with value: 0.22229750652276786 and parameters: {'n_estimators': 245, 'max_depth': 5, 'min_samples_split': 29, 'min_samples_leaf': 12}. Best is trial 16 with value: 0.22229750652276786.\n",
      "[I 2025-06-21 23:16:50,941] Trial 17 finished with value: 0.22276153846588861 and parameters: {'n_estimators': 243, 'max_depth': 4, 'min_samples_split': 29, 'min_samples_leaf': 17}. Best is trial 16 with value: 0.22229750652276786.\n",
      "[I 2025-06-21 23:16:54,276] Trial 18 finished with value: 0.22249143453826276 and parameters: {'n_estimators': 255, 'max_depth': 5, 'min_samples_split': 30, 'min_samples_leaf': 24}. Best is trial 16 with value: 0.22229750652276786.\n",
      "[I 2025-06-21 23:16:55,785] Trial 19 finished with value: 0.22270823673705697 and parameters: {'n_estimators': 130, 'max_depth': 4, 'min_samples_split': 40, 'min_samples_leaf': 12}. Best is trial 16 with value: 0.22229750652276786.\n",
      "[I 2025-06-21 23:16:59,103] Trial 20 finished with value: 0.2223887223497525 and parameters: {'n_estimators': 257, 'max_depth': 5, 'min_samples_split': 31, 'min_samples_leaf': 16}. Best is trial 16 with value: 0.22229750652276786.\n",
      "[I 2025-06-21 23:17:02,763] Trial 21 finished with value: 0.22238578722150923 and parameters: {'n_estimators': 261, 'max_depth': 5, 'min_samples_split': 28, 'min_samples_leaf': 16}. Best is trial 16 with value: 0.22229750652276786.\n",
      "[I 2025-06-21 23:17:05,784] Trial 22 finished with value: 0.22226757575554662 and parameters: {'n_estimators': 228, 'max_depth': 5, 'min_samples_split': 22, 'min_samples_leaf': 13}. Best is trial 22 with value: 0.22226757575554662.\n",
      "[I 2025-06-21 23:17:08,752] Trial 23 finished with value: 0.22230969895978098 and parameters: {'n_estimators': 234, 'max_depth': 5, 'min_samples_split': 22, 'min_samples_leaf': 15}. Best is trial 22 with value: 0.22226757575554662.\n",
      "[I 2025-06-21 23:17:11,308] Trial 24 finished with value: 0.22262959962818485 and parameters: {'n_estimators': 228, 'max_depth': 4, 'min_samples_split': 22, 'min_samples_leaf': 13}. Best is trial 22 with value: 0.22226757575554662.\n",
      "[I 2025-06-21 23:17:14,112] Trial 25 finished with value: 0.22254297213082283 and parameters: {'n_estimators': 221, 'max_depth': 5, 'min_samples_split': 21, 'min_samples_leaf': 21}. Best is trial 22 with value: 0.22226757575554662.\n",
      "[I 2025-06-21 23:17:16,318] Trial 26 finished with value: 0.2226919468971619 and parameters: {'n_estimators': 203, 'max_depth': 4, 'min_samples_split': 25, 'min_samples_leaf': 15}. Best is trial 22 with value: 0.22226757575554662.\n",
      "[I 2025-06-21 23:17:19,978] Trial 27 finished with value: 0.22227767612678342 and parameters: {'n_estimators': 266, 'max_depth': 5, 'min_samples_split': 18, 'min_samples_leaf': 12}. Best is trial 22 with value: 0.22226757575554662.\n",
      "[I 2025-06-21 23:17:22,617] Trial 28 finished with value: 0.2233082936975081 and parameters: {'n_estimators': 279, 'max_depth': 3, 'min_samples_split': 18, 'min_samples_leaf': 11}. Best is trial 22 with value: 0.22226757575554662.\n",
      "[I 2025-06-21 23:17:26,228] Trial 29 finished with value: 0.22231822906958496 and parameters: {'n_estimators': 266, 'max_depth': 5, 'min_samples_split': 32, 'min_samples_leaf': 13}. Best is trial 22 with value: 0.22226757575554662.\n",
      "[I 2025-06-21 23:17:30,099] Trial 30 finished with value: 0.22226552424463533 and parameters: {'n_estimators': 298, 'max_depth': 5, 'min_samples_split': 27, 'min_samples_leaf': 13}. Best is trial 30 with value: 0.22226552424463533.\n",
      "[I 2025-06-21 23:17:33,892] Trial 31 finished with value: 0.2222894378776051 and parameters: {'n_estimators': 289, 'max_depth': 5, 'min_samples_split': 25, 'min_samples_leaf': 13}. Best is trial 30 with value: 0.22226552424463533.\n",
      "[I 2025-06-21 23:17:37,734] Trial 32 finished with value: 0.22244710205915208 and parameters: {'n_estimators': 297, 'max_depth': 5, 'min_samples_split': 26, 'min_samples_leaf': 18}. Best is trial 30 with value: 0.22226552424463533.\n",
      "[I 2025-06-21 23:17:41,324] Trial 33 finished with value: 0.22235726171721018 and parameters: {'n_estimators': 275, 'max_depth': 5, 'min_samples_split': 24, 'min_samples_leaf': 14}. Best is trial 30 with value: 0.22226552424463533.\n",
      "[I 2025-06-21 23:17:44,529] Trial 34 finished with value: 0.222642962718683 and parameters: {'n_estimators': 297, 'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 11}. Best is trial 30 with value: 0.22226552424463533.\n",
      "[I 2025-06-21 23:17:48,385] Trial 35 finished with value: 0.22230234214970582 and parameters: {'n_estimators': 300, 'max_depth': 5, 'min_samples_split': 34, 'min_samples_leaf': 13}. Best is trial 30 with value: 0.22226552424463533.\n",
      "[I 2025-06-21 23:17:51,910] Trial 36 finished with value: 0.22235743525430002 and parameters: {'n_estimators': 270, 'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 15}. Best is trial 30 with value: 0.22226552424463533.\n",
      "[I 2025-06-21 23:17:54,630] Trial 37 finished with value: 0.22278440878564268 and parameters: {'n_estimators': 244, 'max_depth': 4, 'min_samples_split': 26, 'min_samples_leaf': 18}. Best is trial 30 with value: 0.22226552424463533.\n",
      "[I 2025-06-21 23:17:58,208] Trial 38 finished with value: 0.22253895730260628 and parameters: {'n_estimators': 278, 'max_depth': 5, 'min_samples_split': 18, 'min_samples_leaf': 23}. Best is trial 30 with value: 0.22226552424463533.\n",
      "[I 2025-06-21 23:17:58,663] Trial 39 finished with value: 0.2234206400162248 and parameters: {'n_estimators': 49, 'max_depth': 3, 'min_samples_split': 15, 'min_samples_leaf': 11}. Best is trial 30 with value: 0.22226552424463533.\n",
      "[I 2025-06-21 23:18:00,656] Trial 40 finished with value: 0.22425292758603033 and parameters: {'n_estimators': 283, 'max_depth': 2, 'min_samples_split': 41, 'min_samples_leaf': 20}. Best is trial 30 with value: 0.22226552424463533.\n",
      "[I 2025-06-21 23:18:03,981] Trial 41 finished with value: 0.22226727209553815 and parameters: {'n_estimators': 244, 'max_depth': 5, 'min_samples_split': 23, 'min_samples_leaf': 12}. Best is trial 30 with value: 0.22226552424463533.\n",
      "[I 2025-06-21 23:18:06,526] Trial 42 finished with value: 0.22233082046725455 and parameters: {'n_estimators': 206, 'max_depth': 5, 'min_samples_split': 23, 'min_samples_leaf': 14}. Best is trial 30 with value: 0.22226552424463533.\n",
      "[I 2025-06-21 23:18:09,691] Trial 43 finished with value: 0.2222812476525394 and parameters: {'n_estimators': 251, 'max_depth': 5, 'min_samples_split': 27, 'min_samples_leaf': 13}. Best is trial 30 with value: 0.22226552424463533.\n",
      "[I 2025-06-21 23:18:11,869] Trial 44 finished with value: 0.2222754873620607 and parameters: {'n_estimators': 174, 'max_depth': 5, 'min_samples_split': 27, 'min_samples_leaf': 11}. Best is trial 30 with value: 0.22226552424463533.\n",
      "[I 2025-06-21 23:18:14,172] Trial 45 finished with value: 0.22224378976086254 and parameters: {'n_estimators': 175, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 10}. Best is trial 45 with value: 0.22224378976086254.\n",
      "[I 2025-06-21 23:18:16,350] Trial 46 finished with value: 0.22228456390617338 and parameters: {'n_estimators': 167, 'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 10}. Best is trial 45 with value: 0.22224378976086254.\n",
      "[I 2025-06-21 23:18:18,635] Trial 47 finished with value: 0.2223592563321788 and parameters: {'n_estimators': 167, 'max_depth': 5, 'min_samples_split': 34, 'min_samples_leaf': 11}. Best is trial 45 with value: 0.22224378976086254.\n",
      "[I 2025-06-21 23:18:20,331] Trial 48 finished with value: 0.22236668077740457 and parameters: {'n_estimators': 133, 'max_depth': 5, 'min_samples_split': 32, 'min_samples_leaf': 10}. Best is trial 45 with value: 0.22224378976086254.\n",
      "[I 2025-06-21 23:18:22,289] Trial 49 finished with value: 0.2226294001371262 and parameters: {'n_estimators': 177, 'max_depth': 4, 'min_samples_split': 24, 'min_samples_leaf': 11}. Best is trial 45 with value: 0.22224378976086254.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 175, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 10}\n",
      "Best CV MSE: 0.22224378976086254\n"
     ]
    }
   ],
   "source": [
    "preference_mapping = {\n",
    "    1:  (1, 1, 1, 1),\n",
    "    2:  (1, 1, 1, 2),\n",
    "    3:  (1, 1, 2, 1),\n",
    "    4:  (1, 1, 2, 2),\n",
    "    5:  (1, 2, 1, 1),\n",
    "    6:  (1, 2, 1, 2),\n",
    "    7:  (1, 2, 2, 1),\n",
    "    8:  (1, 2, 2, 2),\n",
    "    9:  (2, 1, 1, 1),\n",
    "    10: (2, 1, 1, 2),\n",
    "    11: (2, 1, 2, 1),\n",
    "    12: (2, 1, 2, 2),\n",
    "    13: (2, 2, 1, 1),\n",
    "    14: (2, 2, 1, 2),\n",
    "    15: (2, 2, 2, 1),\n",
    "    16: (2, 2, 2, 2),\n",
    "    17: (0, 0, 0, 0)\n",
    "}\n",
    "\n",
    "def get_meta_features(preference_id):\n",
    "    return preference_mapping[preference_id]\n",
    "\n",
    "def add_weighted_meta_features(row):\n",
    "    prefs = [row['preference_1'], row['preference_2'], row['preference_3']]\n",
    "    weights = [0.5, 0.3, 0.2]\n",
    "    \n",
    "    S_sum = A_sum = O_sum = I_sum = 0.0\n",
    "    \n",
    "    for pref, w in zip(prefs, weights):\n",
    "        S, A, O, I = get_meta_features(pref)\n",
    "        S_sum += w * S\n",
    "        A_sum += w * A\n",
    "        O_sum += w * O\n",
    "        I_sum += w * I\n",
    "    \n",
    "    row['S_weighted'] = S_sum\n",
    "    row['A_weighted'] = A_sum\n",
    "    row['O_weighted'] = O_sum\n",
    "    row['I_weighted'] = I_sum\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "df = profiles.copy()\n",
    "df = df.apply(add_weighted_meta_features, axis=1)\n",
    "\n",
    "features = ['age', 'gender', 'education', 'income', 'marital_status',\n",
    "            'S_weighted', 'A_weighted', 'O_weighted', 'I_weighted']\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess_data(df, categorical_cols, features, target)\n",
    "\n",
    "best_params = optimize_rf_with_optuna(X_train, y_train, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14ddcdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest (socdem + weighted meta): MSE=0.2325, R2=0.0266, train_time=0.5402s, inference_time=0.0130s\n"
     ]
    }
   ],
   "source": [
    "best_rf = RandomForestRegressor(**best_params, random_state=42)\n",
    "results.append(train_and_evaluate(best_rf, \"RandomForest (socdem + weighted meta)\", X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd9e23a",
   "metadata": {},
   "source": [
    "## RF: socdem fetures + one-hot meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a14e9e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 23:18:34,477] A new study created in memory with name: no-name-5dd44ed6-2f4e-4ea1-9d5e-2e1da8fa835d\n",
      "[I 2025-06-21 23:18:35,744] Trial 0 finished with value: 0.22529774363155383 and parameters: {'n_estimators': 177, 'max_depth': 2, 'min_samples_split': 16, 'min_samples_leaf': 13}. Best is trial 0 with value: 0.22529774363155383.\n",
      "[I 2025-06-21 23:18:36,315] Trial 1 finished with value: 0.22269639033413494 and parameters: {'n_estimators': 40, 'max_depth': 5, 'min_samples_split': 58, 'min_samples_leaf': 14}. Best is trial 1 with value: 0.22269639033413494.\n",
      "[I 2025-06-21 23:18:36,610] Trial 2 finished with value: 0.22379708573018836 and parameters: {'n_estimators': 30, 'max_depth': 3, 'min_samples_split': 44, 'min_samples_leaf': 16}. Best is trial 1 with value: 0.22269639033413494.\n",
      "[I 2025-06-21 23:18:37,611] Trial 3 finished with value: 0.22529821189450328 and parameters: {'n_estimators': 138, 'max_depth': 2, 'min_samples_split': 40, 'min_samples_leaf': 26}. Best is trial 1 with value: 0.22269639033413494.\n",
      "[I 2025-06-21 23:18:39,654] Trial 4 finished with value: 0.2238936040910901 and parameters: {'n_estimators': 211, 'max_depth': 3, 'min_samples_split': 57, 'min_samples_leaf': 19}. Best is trial 1 with value: 0.22269639033413494.\n",
      "[I 2025-06-21 23:18:40,724] Trial 5 finished with value: 0.22384513660751332 and parameters: {'n_estimators': 114, 'max_depth': 3, 'min_samples_split': 36, 'min_samples_leaf': 21}. Best is trial 1 with value: 0.22269639033413494.\n",
      "[I 2025-06-21 23:18:41,192] Trial 6 finished with value: 0.22392428181054608 and parameters: {'n_estimators': 48, 'max_depth': 3, 'min_samples_split': 49, 'min_samples_leaf': 18}. Best is trial 1 with value: 0.22269639033413494.\n",
      "[I 2025-06-21 23:18:42,202] Trial 7 finished with value: 0.22385064084862746 and parameters: {'n_estimators': 105, 'max_depth': 3, 'min_samples_split': 20, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.22269639033413494.\n",
      "[I 2025-06-21 23:18:44,730] Trial 8 finished with value: 0.22269457799319464 and parameters: {'n_estimators': 185, 'max_depth': 5, 'min_samples_split': 36, 'min_samples_leaf': 19}. Best is trial 8 with value: 0.22269457799319464.\n",
      "[I 2025-06-21 23:18:46,320] Trial 9 finished with value: 0.22529628990797682 and parameters: {'n_estimators': 221, 'max_depth': 2, 'min_samples_split': 20, 'min_samples_leaf': 12}. Best is trial 8 with value: 0.22269457799319464.\n",
      "[I 2025-06-21 23:18:50,323] Trial 10 finished with value: 0.22267873988281486 and parameters: {'n_estimators': 279, 'max_depth': 5, 'min_samples_split': 31, 'min_samples_leaf': 30}. Best is trial 10 with value: 0.22267873988281486.\n",
      "[I 2025-06-21 23:18:54,545] Trial 11 finished with value: 0.22268972926530295 and parameters: {'n_estimators': 295, 'max_depth': 5, 'min_samples_split': 30, 'min_samples_leaf': 30}. Best is trial 10 with value: 0.22267873988281486.\n",
      "[I 2025-06-21 23:18:58,415] Trial 12 finished with value: 0.22268501258680945 and parameters: {'n_estimators': 293, 'max_depth': 5, 'min_samples_split': 28, 'min_samples_leaf': 30}. Best is trial 10 with value: 0.22267873988281486.\n",
      "[I 2025-06-21 23:19:01,881] Trial 13 finished with value: 0.2230582868541701 and parameters: {'n_estimators': 299, 'max_depth': 4, 'min_samples_split': 28, 'min_samples_leaf': 30}. Best is trial 10 with value: 0.22267873988281486.\n",
      "[I 2025-06-21 23:19:04,831] Trial 14 finished with value: 0.22302837529084987 and parameters: {'n_estimators': 257, 'max_depth': 4, 'min_samples_split': 28, 'min_samples_leaf': 26}. Best is trial 10 with value: 0.22267873988281486.\n",
      "[I 2025-06-21 23:19:07,820] Trial 15 finished with value: 0.22302837529084987 and parameters: {'n_estimators': 257, 'max_depth': 4, 'min_samples_split': 32, 'min_samples_leaf': 26}. Best is trial 10 with value: 0.22267873988281486.\n",
      "[I 2025-06-21 23:19:11,359] Trial 16 finished with value: 0.2226910835036458 and parameters: {'n_estimators': 258, 'max_depth': 5, 'min_samples_split': 23, 'min_samples_leaf': 24}. Best is trial 10 with value: 0.22267873988281486.\n",
      "[I 2025-06-21 23:19:14,063] Trial 17 finished with value: 0.22302463256636282 and parameters: {'n_estimators': 230, 'max_depth': 4, 'min_samples_split': 44, 'min_samples_leaf': 28}. Best is trial 10 with value: 0.22267873988281486.\n",
      "[I 2025-06-21 23:19:18,223] Trial 18 finished with value: 0.2226849727100241 and parameters: {'n_estimators': 289, 'max_depth': 5, 'min_samples_split': 24, 'min_samples_leaf': 24}. Best is trial 10 with value: 0.22267873988281486.\n",
      "[I 2025-06-21 23:19:21,933] Trial 19 finished with value: 0.222683024214491 and parameters: {'n_estimators': 272, 'max_depth': 5, 'min_samples_split': 23, 'min_samples_leaf': 22}. Best is trial 10 with value: 0.22267873988281486.\n",
      "[I 2025-06-21 23:19:25,001] Trial 20 finished with value: 0.22301174191459755 and parameters: {'n_estimators': 247, 'max_depth': 4, 'min_samples_split': 15, 'min_samples_leaf': 22}. Best is trial 10 with value: 0.22267873988281486.\n",
      "[I 2025-06-21 23:19:28,725] Trial 21 finished with value: 0.22269043522255533 and parameters: {'n_estimators': 275, 'max_depth': 5, 'min_samples_split': 24, 'min_samples_leaf': 24}. Best is trial 10 with value: 0.22267873988281486.\n",
      "[I 2025-06-21 23:19:31,437] Trial 22 finished with value: 0.22268101227073514 and parameters: {'n_estimators': 198, 'max_depth': 5, 'min_samples_split': 23, 'min_samples_leaf': 23}. Best is trial 10 with value: 0.22267873988281486.\n",
      "[I 2025-06-21 23:19:34,112] Trial 23 finished with value: 0.22269131919353166 and parameters: {'n_estimators': 193, 'max_depth': 5, 'min_samples_split': 33, 'min_samples_leaf': 22}. Best is trial 10 with value: 0.22267873988281486.\n",
      "[I 2025-06-21 23:19:36,076] Trial 24 finished with value: 0.2229321078110925 and parameters: {'n_estimators': 146, 'max_depth': 4, 'min_samples_split': 19, 'min_samples_leaf': 16}. Best is trial 10 with value: 0.22267873988281486.\n",
      "[I 2025-06-21 23:19:39,562] Trial 25 finished with value: 0.22266353249636078 and parameters: {'n_estimators': 229, 'max_depth': 5, 'min_samples_split': 24, 'min_samples_leaf': 28}. Best is trial 25 with value: 0.22266353249636078.\n",
      "[I 2025-06-21 23:19:42,499] Trial 26 finished with value: 0.2226567202160532 and parameters: {'n_estimators': 204, 'max_depth': 5, 'min_samples_split': 26, 'min_samples_leaf': 28}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:19:45,407] Trial 27 finished with value: 0.22302365814735658 and parameters: {'n_estimators': 229, 'max_depth': 4, 'min_samples_split': 33, 'min_samples_leaf': 28}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:19:48,758] Trial 28 finished with value: 0.2226568976186972 and parameters: {'n_estimators': 235, 'max_depth': 5, 'min_samples_split': 39, 'min_samples_leaf': 28}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:19:50,726] Trial 29 finished with value: 0.22300803249849813 and parameters: {'n_estimators': 165, 'max_depth': 4, 'min_samples_split': 42, 'min_samples_leaf': 28}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:19:53,126] Trial 30 finished with value: 0.2226570717556111 and parameters: {'n_estimators': 174, 'max_depth': 5, 'min_samples_split': 50, 'min_samples_leaf': 27}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:19:55,650] Trial 31 finished with value: 0.2226679207679449 and parameters: {'n_estimators': 177, 'max_depth': 5, 'min_samples_split': 53, 'min_samples_leaf': 27}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:19:58,553] Trial 32 finished with value: 0.22265783398700786 and parameters: {'n_estimators': 205, 'max_depth': 5, 'min_samples_split': 50, 'min_samples_leaf': 28}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:01,541] Trial 33 finished with value: 0.22268435598686528 and parameters: {'n_estimators': 206, 'max_depth': 5, 'min_samples_split': 49, 'min_samples_leaf': 25}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:03,900] Trial 34 finished with value: 0.22267498668275384 and parameters: {'n_estimators': 162, 'max_depth': 5, 'min_samples_split': 60, 'min_samples_leaf': 29}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:05,782] Trial 35 finished with value: 0.22269711354074517 and parameters: {'n_estimators': 142, 'max_depth': 5, 'min_samples_split': 51, 'min_samples_leaf': 27}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:07,221] Trial 36 finished with value: 0.2227069748051916 and parameters: {'n_estimators': 108, 'max_depth': 5, 'min_samples_split': 47, 'min_samples_leaf': 25}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:09,332] Trial 37 finished with value: 0.22299288088322805 and parameters: {'n_estimators': 179, 'max_depth': 4, 'min_samples_split': 55, 'min_samples_leaf': 27}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:10,887] Trial 38 finished with value: 0.22528223792719332 and parameters: {'n_estimators': 212, 'max_depth': 2, 'min_samples_split': 39, 'min_samples_leaf': 29}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:12,056] Trial 39 finished with value: 0.22276459231556783 and parameters: {'n_estimators': 83, 'max_depth': 5, 'min_samples_split': 45, 'min_samples_leaf': 25}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:13,786] Trial 40 finished with value: 0.222703382567398 and parameters: {'n_estimators': 126, 'max_depth': 5, 'min_samples_split': 56, 'min_samples_leaf': 29}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:17,172] Trial 41 finished with value: 0.22265795741642283 and parameters: {'n_estimators': 232, 'max_depth': 5, 'min_samples_split': 41, 'min_samples_leaf': 28}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:20,708] Trial 42 finished with value: 0.22266813717511988 and parameters: {'n_estimators': 244, 'max_depth': 5, 'min_samples_split': 37, 'min_samples_leaf': 27}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:23,673] Trial 43 finished with value: 0.22266510196503506 and parameters: {'n_estimators': 210, 'max_depth': 5, 'min_samples_split': 40, 'min_samples_leaf': 26}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:26,486] Trial 44 finished with value: 0.222658004761818 and parameters: {'n_estimators': 193, 'max_depth': 5, 'min_samples_split': 46, 'min_samples_leaf': 29}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:29,766] Trial 45 finished with value: 0.22266923316603698 and parameters: {'n_estimators': 241, 'max_depth': 5, 'min_samples_split': 42, 'min_samples_leaf': 26}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:31,453] Trial 46 finished with value: 0.22382111878472802 and parameters: {'n_estimators': 172, 'max_depth': 3, 'min_samples_split': 49, 'min_samples_leaf': 30}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:34,437] Trial 47 finished with value: 0.2226947937379212 and parameters: {'n_estimators': 218, 'max_depth': 5, 'min_samples_split': 42, 'min_samples_leaf': 17}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:36,320] Trial 48 finished with value: 0.22295963640565025 and parameters: {'n_estimators': 155, 'max_depth': 4, 'min_samples_split': 35, 'min_samples_leaf': 20}. Best is trial 26 with value: 0.2226567202160532.\n",
      "[I 2025-06-21 23:20:38,159] Trial 49 finished with value: 0.2238235548010699 and parameters: {'n_estimators': 188, 'max_depth': 3, 'min_samples_split': 52, 'min_samples_leaf': 28}. Best is trial 26 with value: 0.2226567202160532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 204, 'max_depth': 5, 'min_samples_split': 26, 'min_samples_leaf': 28}\n",
      "Best CV MSE: 0.2226567202160532\n"
     ]
    }
   ],
   "source": [
    "def add_full_meta_features(row):\n",
    "    prefs = [row['preference_1'], row['preference_2'], row['preference_3']]\n",
    "    \n",
    "    for idx, pref in enumerate(prefs, start=1):\n",
    "        S, A, O, I = preference_mapping[pref]\n",
    "        row[f'S{idx}'] = S\n",
    "        row[f'A{idx}'] = A\n",
    "        row[f'O{idx}'] = O\n",
    "        row[f'I{idx}'] = I\n",
    "        \n",
    "    return row\n",
    "\n",
    "df_onehot = profiles.copy()\n",
    "df_onehot = df_onehot.apply(add_full_meta_features, axis=1)\n",
    "\n",
    "features_onehot = [\n",
    "    'age', 'gender', 'education', 'income', 'marital_status',\n",
    "    'S1', 'A1', 'O1', 'I1',\n",
    "    'S2', 'A2', 'O2', 'I2',\n",
    "    'S3', 'A3', 'O3', 'I3'\n",
    "]\n",
    "X_train, X_test, y_train, y_test = preprocess_data(df_onehot, categorical_cols, features_onehot, target)\n",
    "\n",
    "best_params = optimize_rf_with_optuna(X_train, y_train, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99e27133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest (socdem + one-hot meta): MSE=0.2320, R2=0.0284, train_time=0.7132s, inference_time=0.0161s\n"
     ]
    }
   ],
   "source": [
    "best_rf = RandomForestRegressor(**best_params, random_state=42)\n",
    "results.append(train_and_evaluate(best_rf, \"RandomForest (socdem + one-hot meta)\", X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b21e9",
   "metadata": {},
   "source": [
    "## RF: only meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5046bfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 23:20:50,670] A new study created in memory with name: no-name-a9da37de-1a7d-4b3d-bab6-f0020b304049\n",
      "[I 2025-06-21 23:20:51,299] Trial 0 finished with value: 0.22377564498998934 and parameters: {'n_estimators': 118, 'max_depth': 3, 'min_samples_split': 44, 'min_samples_leaf': 16}. Best is trial 0 with value: 0.22377564498998934.\n",
      "[I 2025-06-21 23:20:52,534] Trial 1 finished with value: 0.2230041338337811 and parameters: {'n_estimators': 208, 'max_depth': 4, 'min_samples_split': 30, 'min_samples_leaf': 29}. Best is trial 1 with value: 0.2230041338337811.\n",
      "[I 2025-06-21 23:20:54,039] Trial 2 finished with value: 0.22298172394132765 and parameters: {'n_estimators': 257, 'max_depth': 4, 'min_samples_split': 50, 'min_samples_leaf': 21}. Best is trial 2 with value: 0.22298172394132765.\n",
      "[I 2025-06-21 23:20:54,811] Trial 3 finished with value: 0.22527157431628067 and parameters: {'n_estimators': 172, 'max_depth': 2, 'min_samples_split': 40, 'min_samples_leaf': 20}. Best is trial 2 with value: 0.22298172394132765.\n",
      "[I 2025-06-21 23:20:55,306] Trial 4 finished with value: 0.22304838648144915 and parameters: {'n_estimators': 83, 'max_depth': 4, 'min_samples_split': 50, 'min_samples_leaf': 29}. Best is trial 2 with value: 0.22298172394132765.\n",
      "[I 2025-06-21 23:20:55,927] Trial 5 finished with value: 0.22528928176256505 and parameters: {'n_estimators': 138, 'max_depth': 2, 'min_samples_split': 59, 'min_samples_leaf': 17}. Best is trial 2 with value: 0.22298172394132765.\n",
      "[I 2025-06-21 23:20:57,263] Trial 6 finished with value: 0.22378695735558116 and parameters: {'n_estimators': 245, 'max_depth': 3, 'min_samples_split': 23, 'min_samples_leaf': 14}. Best is trial 2 with value: 0.22298172394132765.\n",
      "[I 2025-06-21 23:20:58,510] Trial 7 finished with value: 0.22377166644539903 and parameters: {'n_estimators': 227, 'max_depth': 3, 'min_samples_split': 23, 'min_samples_leaf': 15}. Best is trial 2 with value: 0.22298172394132765.\n",
      "[I 2025-06-21 23:20:59,861] Trial 8 finished with value: 0.22527176120393744 and parameters: {'n_estimators': 286, 'max_depth': 2, 'min_samples_split': 48, 'min_samples_leaf': 21}. Best is trial 2 with value: 0.22298172394132765.\n",
      "[I 2025-06-21 23:21:01,051] Trial 9 finished with value: 0.22377165211529165 and parameters: {'n_estimators': 209, 'max_depth': 3, 'min_samples_split': 50, 'min_samples_leaf': 14}. Best is trial 2 with value: 0.22298172394132765.\n",
      "[I 2025-06-21 23:21:01,249] Trial 10 finished with value: 0.22280072532506762 and parameters: {'n_estimators': 27, 'max_depth': 5, 'min_samples_split': 60, 'min_samples_leaf': 24}. Best is trial 10 with value: 0.22280072532506762.\n",
      "[I 2025-06-21 23:21:01,434] Trial 11 finished with value: 0.2227807972209872 and parameters: {'n_estimators': 25, 'max_depth': 5, 'min_samples_split': 60, 'min_samples_leaf': 24}. Best is trial 11 with value: 0.2227807972209872.\n",
      "[I 2025-06-21 23:21:01,606] Trial 12 finished with value: 0.22280987709149938 and parameters: {'n_estimators': 22, 'max_depth': 5, 'min_samples_split': 60, 'min_samples_leaf': 25}. Best is trial 11 with value: 0.2227807972209872.\n",
      "[I 2025-06-21 23:21:01,813] Trial 13 finished with value: 0.22281447552512942 and parameters: {'n_estimators': 27, 'max_depth': 5, 'min_samples_split': 56, 'min_samples_leaf': 25}. Best is trial 11 with value: 0.2227807972209872.\n",
      "[I 2025-06-21 23:21:02,286] Trial 14 finished with value: 0.22276564919115843 and parameters: {'n_estimators': 64, 'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 25}. Best is trial 14 with value: 0.22276564919115843.\n",
      "[I 2025-06-21 23:21:02,820] Trial 15 finished with value: 0.22283285988306362 and parameters: {'n_estimators': 73, 'max_depth': 5, 'min_samples_split': 33, 'min_samples_leaf': 10}. Best is trial 14 with value: 0.22276564919115843.\n",
      "[I 2025-06-21 23:21:03,288] Trial 16 finished with value: 0.22306553868497128 and parameters: {'n_estimators': 73, 'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 27}. Best is trial 14 with value: 0.22276564919115843.\n",
      "[I 2025-06-21 23:21:04,014] Trial 17 finished with value: 0.2227778871676141 and parameters: {'n_estimators': 108, 'max_depth': 5, 'min_samples_split': 16, 'min_samples_leaf': 23}. Best is trial 14 with value: 0.22276564919115843.\n",
      "[I 2025-06-21 23:21:04,830] Trial 18 finished with value: 0.2228074564653816 and parameters: {'n_estimators': 102, 'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 22}. Best is trial 14 with value: 0.22276564919115843.\n",
      "[I 2025-06-21 23:21:06,065] Trial 19 finished with value: 0.22298026751899785 and parameters: {'n_estimators': 165, 'max_depth': 4, 'min_samples_split': 24, 'min_samples_leaf': 27}. Best is trial 14 with value: 0.22276564919115843.\n",
      "[I 2025-06-21 23:21:06,452] Trial 20 finished with value: 0.22279551556561858 and parameters: {'n_estimators': 55, 'max_depth': 5, 'min_samples_split': 29, 'min_samples_leaf': 18}. Best is trial 14 with value: 0.22276564919115843.\n",
      "[I 2025-06-21 23:21:06,788] Trial 21 finished with value: 0.2228307647290489 and parameters: {'n_estimators': 47, 'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 23}. Best is trial 14 with value: 0.22276564919115843.\n",
      "[I 2025-06-21 23:21:07,530] Trial 22 finished with value: 0.22275240367209692 and parameters: {'n_estimators': 111, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 27}. Best is trial 22 with value: 0.22275240367209692.\n",
      "[I 2025-06-21 23:21:08,309] Trial 23 finished with value: 0.22300923916690762 and parameters: {'n_estimators': 131, 'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 27}. Best is trial 22 with value: 0.22275240367209692.\n",
      "[I 2025-06-21 23:21:09,022] Trial 24 finished with value: 0.22276254220675984 and parameters: {'n_estimators': 102, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 26}. Best is trial 22 with value: 0.22275240367209692.\n",
      "[I 2025-06-21 23:21:09,641] Trial 25 finished with value: 0.22274891586161943 and parameters: {'n_estimators': 91, 'max_depth': 5, 'min_samples_split': 27, 'min_samples_leaf': 30}. Best is trial 25 with value: 0.22274891586161943.\n",
      "[I 2025-06-21 23:21:10,256] Trial 26 finished with value: 0.2230573919871826 and parameters: {'n_estimators': 94, 'max_depth': 4, 'min_samples_split': 27, 'min_samples_leaf': 30}. Best is trial 25 with value: 0.22274891586161943.\n",
      "[I 2025-06-21 23:21:11,204] Trial 27 finished with value: 0.22270065999461472 and parameters: {'n_estimators': 144, 'max_depth': 5, 'min_samples_split': 34, 'min_samples_leaf': 30}. Best is trial 27 with value: 0.22270065999461472.\n",
      "[I 2025-06-21 23:21:12,101] Trial 28 finished with value: 0.22302792315989403 and parameters: {'n_estimators': 149, 'max_depth': 4, 'min_samples_split': 36, 'min_samples_leaf': 30}. Best is trial 27 with value: 0.22270065999461472.\n",
      "[I 2025-06-21 23:21:12,941] Trial 29 finished with value: 0.22273206716202823 and parameters: {'n_estimators': 122, 'max_depth': 5, 'min_samples_split': 40, 'min_samples_leaf': 28}. Best is trial 27 with value: 0.22270065999461472.\n",
      "[I 2025-06-21 23:21:14,091] Trial 30 finished with value: 0.22268726218940643 and parameters: {'n_estimators': 176, 'max_depth': 5, 'min_samples_split': 42, 'min_samples_leaf': 29}. Best is trial 30 with value: 0.22268726218940643.\n",
      "[I 2025-06-21 23:21:15,288] Trial 31 finished with value: 0.22268283717133527 and parameters: {'n_estimators': 185, 'max_depth': 5, 'min_samples_split': 40, 'min_samples_leaf': 29}. Best is trial 31 with value: 0.22268283717133527.\n",
      "[I 2025-06-21 23:21:16,527] Trial 32 finished with value: 0.22270409170440839 and parameters: {'n_estimators': 180, 'max_depth': 5, 'min_samples_split': 42, 'min_samples_leaf': 28}. Best is trial 31 with value: 0.22268283717133527.\n",
      "[I 2025-06-21 23:21:17,728] Trial 33 finished with value: 0.22298638266998708 and parameters: {'n_estimators': 186, 'max_depth': 4, 'min_samples_split': 43, 'min_samples_leaf': 29}. Best is trial 31 with value: 0.22268283717133527.\n",
      "[I 2025-06-21 23:21:19,076] Trial 34 finished with value: 0.2226982641369848 and parameters: {'n_estimators': 188, 'max_depth': 5, 'min_samples_split': 36, 'min_samples_leaf': 28}. Best is trial 31 with value: 0.22268283717133527.\n",
      "[I 2025-06-21 23:21:20,470] Trial 35 finished with value: 0.22268388904901198 and parameters: {'n_estimators': 204, 'max_depth': 5, 'min_samples_split': 35, 'min_samples_leaf': 29}. Best is trial 31 with value: 0.22268283717133527.\n",
      "[I 2025-06-21 23:21:21,854] Trial 36 finished with value: 0.22300097912839675 and parameters: {'n_estimators': 207, 'max_depth': 4, 'min_samples_split': 46, 'min_samples_leaf': 28}. Best is trial 31 with value: 0.22268283717133527.\n",
      "[I 2025-06-21 23:21:23,233] Trial 37 finished with value: 0.22267674371775778 and parameters: {'n_estimators': 196, 'max_depth': 5, 'min_samples_split': 38, 'min_samples_leaf': 29}. Best is trial 37 with value: 0.22267674371775778.\n",
      "[I 2025-06-21 23:21:24,544] Trial 38 finished with value: 0.22298121871977045 and parameters: {'n_estimators': 202, 'max_depth': 4, 'min_samples_split': 39, 'min_samples_leaf': 26}. Best is trial 37 with value: 0.22267674371775778.\n",
      "[I 2025-06-21 23:21:26,073] Trial 39 finished with value: 0.22268561709636825 and parameters: {'n_estimators': 233, 'max_depth': 5, 'min_samples_split': 32, 'min_samples_leaf': 29}. Best is trial 37 with value: 0.22267674371775778.\n",
      "[I 2025-06-21 23:21:27,740] Trial 40 finished with value: 0.2238111932244657 and parameters: {'n_estimators': 255, 'max_depth': 3, 'min_samples_split': 32, 'min_samples_leaf': 29}. Best is trial 37 with value: 0.22267674371775778.\n",
      "[I 2025-06-21 23:21:29,407] Trial 41 finished with value: 0.2226956218702137 and parameters: {'n_estimators': 241, 'max_depth': 5, 'min_samples_split': 37, 'min_samples_leaf': 29}. Best is trial 37 with value: 0.22267674371775778.\n",
      "[I 2025-06-21 23:21:30,920] Trial 42 finished with value: 0.22267788702346256 and parameters: {'n_estimators': 222, 'max_depth': 5, 'min_samples_split': 42, 'min_samples_leaf': 29}. Best is trial 37 with value: 0.22267674371775778.\n",
      "[I 2025-06-21 23:21:32,418] Trial 43 finished with value: 0.22268452439765643 and parameters: {'n_estimators': 221, 'max_depth': 5, 'min_samples_split': 45, 'min_samples_leaf': 26}. Best is trial 37 with value: 0.22267674371775778.\n",
      "[I 2025-06-21 23:21:34,374] Trial 44 finished with value: 0.2227164323914373 and parameters: {'n_estimators': 281, 'max_depth': 5, 'min_samples_split': 45, 'min_samples_leaf': 26}. Best is trial 37 with value: 0.22267674371775778.\n",
      "[I 2025-06-21 23:21:35,388] Trial 45 finished with value: 0.22528052642092736 and parameters: {'n_estimators': 219, 'max_depth': 2, 'min_samples_split': 54, 'min_samples_leaf': 28}. Best is trial 37 with value: 0.22267674371775778.\n",
      "[I 2025-06-21 23:21:36,688] Trial 46 finished with value: 0.22266214804586948 and parameters: {'n_estimators': 197, 'max_depth': 5, 'min_samples_split': 39, 'min_samples_leaf': 30}. Best is trial 46 with value: 0.22266214804586948.\n",
      "[I 2025-06-21 23:21:37,883] Trial 47 finished with value: 0.22299697940318258 and parameters: {'n_estimators': 192, 'max_depth': 4, 'min_samples_split': 40, 'min_samples_leaf': 30}. Best is trial 46 with value: 0.22266214804586948.\n",
      "[I 2025-06-21 23:21:39,044] Trial 48 finished with value: 0.22276600100422805 and parameters: {'n_estimators': 165, 'max_depth': 5, 'min_samples_split': 48, 'min_samples_leaf': 20}. Best is trial 46 with value: 0.22266214804586948.\n",
      "[I 2025-06-21 23:21:40,955] Trial 49 finished with value: 0.22282985635683872 and parameters: {'n_estimators': 272, 'max_depth': 5, 'min_samples_split': 38, 'min_samples_leaf': 10}. Best is trial 46 with value: 0.22266214804586948.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 197, 'max_depth': 5, 'min_samples_split': 39, 'min_samples_leaf': 30}\n",
      "Best CV MSE: 0.22266214804586948\n"
     ]
    }
   ],
   "source": [
    "df_metaonly = profiles.copy()\n",
    "df_metaonly = df_metaonly.apply(add_full_meta_features, axis=1)\n",
    "\n",
    "features_metaonly = [\n",
    "    'S1', 'A1', 'O1', 'I1',\n",
    "    'S2', 'A2', 'O2', 'I2',\n",
    "    'S3', 'A3', 'O3', 'I3'\n",
    "]\n",
    "\n",
    "categorical_cols_metaonly = []\n",
    "X_train, X_test, y_train, y_test = preprocess_data(df_metaonly, categorical_cols_metaonly, features_metaonly, target)\n",
    "\n",
    "best_params = optimize_rf_with_optuna(X_train, y_train, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dcc1ae8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest (meta only): MSE=0.2320, R2=0.0284, train_time=0.3075s, inference_time=0.0137s\n"
     ]
    }
   ],
   "source": [
    "best_rf = RandomForestRegressor(**best_params, random_state=42)\n",
    "results.append(train_and_evaluate(best_rf, \"RandomForest (meta only)\", X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d1c4d",
   "metadata": {},
   "source": [
    "## RF: text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "913b7cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(\n",
    "    df, embeddings, \n",
    "    num_columns, \n",
    "    cat_columns, \n",
    "    target_column, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    "):\n",
    "    pref_1_embs = np.array([embeddings[x] for x in df['preference_1']])\n",
    "    pref_2_embs = np.array([embeddings[x] for x in df['preference_2']])\n",
    "    pref_3_embs = np.array([embeddings[x] for x in df['preference_3']])\n",
    "    emb_features = np.hstack([pref_1_embs, pref_2_embs, pref_3_embs])\n",
    "\n",
    "    if num_columns:\n",
    "        numeric_features = df[num_columns].values\n",
    "    else:\n",
    "        numeric_features = np.zeros((emb_features.shape[0], 0))\n",
    "\n",
    "    if cat_columns:\n",
    "        categorical_features_list = []\n",
    "        for col in cat_columns:\n",
    "            le = LabelEncoder()\n",
    "            encoded_col = le.fit_transform(df[col])\n",
    "            encoded_col = encoded_col.reshape(-1, 1)\n",
    "            categorical_features_list.append(encoded_col)\n",
    "        categorical_features = np.hstack(categorical_features_list)\n",
    "    else:\n",
    "        categorical_features = np.zeros((emb_features.shape[0], 0))\n",
    "\n",
    "    X = np.hstack([emb_features, numeric_features, categorical_features])\n",
    "    y = df[target_column].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6dc8393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_embeddings(description_mapping):\n",
    "\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    text_embeddings = {}\n",
    "    for img_id, description in description_mapping.items():\n",
    "        embedding = model.encode(description)\n",
    "        text_embeddings[img_id] = embedding\n",
    "\n",
    "    return text_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c505d55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-21 23:21:44,223] A new study created in memory with name: no-name-8bb0e349-bf67-4e24-bf78-adc53d408fde\n",
      "[I 2025-06-21 23:24:48,611] Trial 0 finished with value: 0.22187386422018704 and parameters: {'n_estimators': 300, 'max_depth': 4, 'min_samples_split': 38, 'min_samples_leaf': 30}. Best is trial 0 with value: 0.22187386422018704.\n",
      "[I 2025-06-21 23:25:53,754] Trial 1 finished with value: 0.22154451329139224 and parameters: {'n_estimators': 88, 'max_depth': 5, 'min_samples_split': 24, 'min_samples_leaf': 29}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:27:31,049] Trial 2 finished with value: 0.22418113582706164 and parameters: {'n_estimators': 277, 'max_depth': 2, 'min_samples_split': 32, 'min_samples_leaf': 14}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:28:17,749] Trial 3 finished with value: 0.22195677246800835 and parameters: {'n_estimators': 80, 'max_depth': 4, 'min_samples_split': 38, 'min_samples_leaf': 27}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:28:38,503] Trial 4 finished with value: 0.22442473133530286 and parameters: {'n_estimators': 63, 'max_depth': 2, 'min_samples_split': 28, 'min_samples_leaf': 20}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:29:27,309] Trial 5 finished with value: 0.2220201920671149 and parameters: {'n_estimators': 67, 'max_depth': 5, 'min_samples_split': 32, 'min_samples_leaf': 15}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:30:28,404] Trial 6 finished with value: 0.22215137428023501 and parameters: {'n_estimators': 99, 'max_depth': 4, 'min_samples_split': 55, 'min_samples_leaf': 13}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:32:10,497] Trial 7 finished with value: 0.22418077407574769 and parameters: {'n_estimators': 290, 'max_depth': 2, 'min_samples_split': 46, 'min_samples_leaf': 29}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:32:25,967] Trial 8 finished with value: 0.22217093906419444 and parameters: {'n_estimators': 27, 'max_depth': 4, 'min_samples_split': 45, 'min_samples_leaf': 28}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:33:57,089] Trial 9 finished with value: 0.22194506003156683 and parameters: {'n_estimators': 134, 'max_depth': 5, 'min_samples_split': 17, 'min_samples_leaf': 14}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:35:27,885] Trial 10 finished with value: 0.22278201748700752 and parameters: {'n_estimators': 191, 'max_depth': 3, 'min_samples_split': 15, 'min_samples_leaf': 23}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:37:44,437] Trial 11 finished with value: 0.22163546048506905 and parameters: {'n_estimators': 206, 'max_depth': 5, 'min_samples_split': 23, 'min_samples_leaf': 24}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:40:00,744] Trial 12 finished with value: 0.22163065388106595 and parameters: {'n_estimators': 205, 'max_depth': 5, 'min_samples_split': 23, 'min_samples_leaf': 24}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:42:26,167] Trial 13 finished with value: 0.22162420838420777 and parameters: {'n_estimators': 221, 'max_depth': 5, 'min_samples_split': 25, 'min_samples_leaf': 24}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:43:38,588] Trial 14 finished with value: 0.2228119915802742 and parameters: {'n_estimators': 161, 'max_depth': 3, 'min_samples_split': 23, 'min_samples_leaf': 20}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:46:40,252] Trial 15 finished with value: 0.22161270119056536 and parameters: {'n_estimators': 240, 'max_depth': 5, 'min_samples_split': 29, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:50:05,459] Trial 16 finished with value: 0.22162408293928065 and parameters: {'n_estimators': 249, 'max_depth': 5, 'min_samples_split': 31, 'min_samples_leaf': 26}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:51:07,138] Trial 17 finished with value: 0.2229096913663846 and parameters: {'n_estimators': 124, 'max_depth': 3, 'min_samples_split': 44, 'min_samples_leaf': 18}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:52:42,546] Trial 18 finished with value: 0.22185529633963866 and parameters: {'n_estimators': 170, 'max_depth': 4, 'min_samples_split': 19, 'min_samples_leaf': 26}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:55:33,599] Trial 19 finished with value: 0.2219212789137079 and parameters: {'n_estimators': 244, 'max_depth': 5, 'min_samples_split': 35, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:56:45,285] Trial 20 finished with value: 0.22198145768377323 and parameters: {'n_estimators': 124, 'max_depth': 4, 'min_samples_split': 57, 'min_samples_leaf': 22}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-21 23:59:33,802] Trial 21 finished with value: 0.22162872531166528 and parameters: {'n_estimators': 250, 'max_depth': 5, 'min_samples_split': 29, 'min_samples_leaf': 26}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-22 00:02:25,754] Trial 22 finished with value: 0.2215503322618566 and parameters: {'n_estimators': 244, 'max_depth': 5, 'min_samples_split': 28, 'min_samples_leaf': 30}. Best is trial 1 with value: 0.22154451329139224.\n",
      "[I 2025-06-22 00:04:59,400] Trial 23 finished with value: 0.22153670283190827 and parameters: {'n_estimators': 226, 'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 30}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:05:27,910] Trial 24 finished with value: 0.22173931981218004 and parameters: {'n_estimators': 41, 'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 29}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:07:10,448] Trial 25 finished with value: 0.2218027267688302 and parameters: {'n_estimators': 179, 'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 30}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:10:09,091] Trial 26 finished with value: 0.22159913015605404 and parameters: {'n_estimators': 271, 'max_depth': 5, 'min_samples_split': 25, 'min_samples_leaf': 28}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:11:26,995] Trial 27 finished with value: 0.22182652519695809 and parameters: {'n_estimators': 143, 'max_depth': 4, 'min_samples_split': 15, 'min_samples_leaf': 30}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:13:50,164] Trial 28 finished with value: 0.22157530680341933 and parameters: {'n_estimators': 224, 'max_depth': 5, 'min_samples_split': 26, 'min_samples_leaf': 28}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:14:38,996] Trial 29 finished with value: 0.22283716881775634 and parameters: {'n_estimators': 108, 'max_depth': 3, 'min_samples_split': 41, 'min_samples_leaf': 30}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:16:00,920] Trial 30 finished with value: 0.22184659556801473 and parameters: {'n_estimators': 150, 'max_depth': 4, 'min_samples_split': 35, 'min_samples_leaf': 27}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:18:24,906] Trial 31 finished with value: 0.2215768770304931 and parameters: {'n_estimators': 226, 'max_depth': 5, 'min_samples_split': 26, 'min_samples_leaf': 28}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:21:14,469] Trial 32 finished with value: 0.22156248190904898 and parameters: {'n_estimators': 266, 'max_depth': 5, 'min_samples_split': 21, 'min_samples_leaf': 30}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:24:04,752] Trial 33 finished with value: 0.2215679554956922 and parameters: {'n_estimators': 269, 'max_depth': 5, 'min_samples_split': 21, 'min_samples_leaf': 30}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:27:10,812] Trial 34 finished with value: 0.2215813558459248 and parameters: {'n_estimators': 291, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 29}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:29:34,878] Trial 35 finished with value: 0.22187426271062494 and parameters: {'n_estimators': 263, 'max_depth': 4, 'min_samples_split': 17, 'min_samples_leaf': 27}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:32:44,797] Trial 36 finished with value: 0.22159004125576542 and parameters: {'n_estimators': 299, 'max_depth': 5, 'min_samples_split': 34, 'min_samples_leaf': 29}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:33:37,418] Trial 37 finished with value: 0.22190974864771107 and parameters: {'n_estimators': 80, 'max_depth': 5, 'min_samples_split': 28, 'min_samples_leaf': 17}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:34:40,985] Trial 38 finished with value: 0.22421375986722775 and parameters: {'n_estimators': 204, 'max_depth': 2, 'min_samples_split': 22, 'min_samples_leaf': 30}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:37:13,127] Trial 39 finished with value: 0.22196004146469903 and parameters: {'n_estimators': 281, 'max_depth': 4, 'min_samples_split': 31, 'min_samples_leaf': 22}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:39:43,287] Trial 40 finished with value: 0.22156738593709865 and parameters: {'n_estimators': 232, 'max_depth': 5, 'min_samples_split': 48, 'min_samples_leaf': 27}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:42:41,845] Trial 41 finished with value: 0.22157681731348297 and parameters: {'n_estimators': 260, 'max_depth': 5, 'min_samples_split': 48, 'min_samples_leaf': 27}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:45:17,307] Trial 42 finished with value: 0.22156940401137892 and parameters: {'n_estimators': 230, 'max_depth': 5, 'min_samples_split': 50, 'min_samples_leaf': 28}. Best is trial 23 with value: 0.22153670283190827.\n",
      "[I 2025-06-22 00:47:24,070] Trial 43 finished with value: 0.22151257474825795 and parameters: {'n_estimators': 196, 'max_depth': 5, 'min_samples_split': 53, 'min_samples_leaf': 29}. Best is trial 43 with value: 0.22151257474825795.\n",
      "[I 2025-06-22 00:49:27,339] Trial 44 finished with value: 0.22150953708006682 and parameters: {'n_estimators': 190, 'max_depth': 5, 'min_samples_split': 60, 'min_samples_leaf': 29}. Best is trial 44 with value: 0.22150953708006682.\n",
      "[I 2025-06-22 00:51:29,410] Trial 45 finished with value: 0.22150710661926346 and parameters: {'n_estimators': 188, 'max_depth': 5, 'min_samples_split': 60, 'min_samples_leaf': 29}. Best is trial 45 with value: 0.22150710661926346.\n",
      "[I 2025-06-22 00:53:33,564] Trial 46 finished with value: 0.2215694703175167 and parameters: {'n_estimators': 193, 'max_depth': 5, 'min_samples_split': 59, 'min_samples_leaf': 25}. Best is trial 45 with value: 0.22150710661926346.\n",
      "[I 2025-06-22 00:55:22,998] Trial 47 finished with value: 0.22184166771320624 and parameters: {'n_estimators': 189, 'max_depth': 4, 'min_samples_split': 53, 'min_samples_leaf': 29}. Best is trial 45 with value: 0.22150710661926346.\n",
      "[I 2025-06-22 00:57:48,271] Trial 48 finished with value: 0.22154930549561613 and parameters: {'n_estimators': 212, 'max_depth': 5, 'min_samples_split': 60, 'min_samples_leaf': 29}. Best is trial 45 with value: 0.22150710661926346.\n",
      "[I 2025-06-22 00:59:43,455] Trial 49 finished with value: 0.22156759694665915 and parameters: {'n_estimators': 173, 'max_depth': 5, 'min_samples_split': 54, 'min_samples_leaf': 26}. Best is trial 45 with value: 0.22150710661926346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 188, 'max_depth': 5, 'min_samples_split': 60, 'min_samples_leaf': 29}\n",
      "Best CV MSE: 0.22150710661926346\n"
     ]
    }
   ],
   "source": [
    "description_mapping = {\n",
    "    1: \"Orderly courtyard. Knights march in sync. Donkey gives commands. Farquaad measures with ruler. Clean pastel tones.\",\n",
    "    2: \"Shrek trains alone in clean gym. Hits straw dummy. Fight schedule on wall. Dull skyline. Pastel light.\",\n",
    "    3: \"Chaos in throne room after party. Broken dishes. Princess on chandelier. Donkey DJs. Shrek facepalms.\",\n",
    "    4: \"Shrek in dungeon. Broken cages. Graffiti 'Puss was here'. Dramatic shadows from torchlight.\",\n",
    "    5: \"Farquaad drinks tea in empty hall. Parade outside. Banner 'Order is Power'.\",\n",
    "    6: \"Shrek reads 'How to Be Human' in library. Warm lamp. Coffee cup.\",\n",
    "    7: \"Everyone sleeps after party. Shrek in crown. Donkey hugs keg.\",\n",
    "    8: \"Shrek naps in carriage. Unicorns pull. Books and teacup inside.\",\n",
    "    9: \"Shrek, Fiona, Donkey race in swamp. Flags. Cartoon lighting.\",\n",
    "    10: \"Shrek chops wood neatly. Fiona watches. Calm forest.\",\n",
    "    11: \"Tavern party. Trolls dance. Donkey sings. Spilled drinks.\",\n",
    "    12: \"Shrek puts out fire. Puss cleans himself nearby. 'No Entry' sign.\",\n",
    "    13: \"Family picnic in swamp. Donkey entertains piglets. Lanterns, baskets.\",\n",
    "    14: \"Shrek naps in hammock. Bird holds sign. Puss asleep.\",\n",
    "    15: \"Campfire talk. Group laughs and argues. Snacks around.\",\n",
    "    16: \"Shrek lies in puddle. Frogs jump. 'Life is good' sign.\",\n",
    "    17: \"Everyone stands in line near outhouse. No action. Donkey stares at hourglass.\"\n",
    "    }\n",
    "\n",
    "text_embeddings = create_text_embeddings(description_mapping)\n",
    "\n",
    "cat_columns = ['gender', 'education', 'income', 'marital_status']\n",
    "num_columns = ['age']\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_features(\n",
    "    profiles, text_embeddings, num_columns, cat_columns, target\n",
    ")\n",
    "\n",
    "best_params = optimize_rf_with_optuna(X_train, y_train, n_trials=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2cc5757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest (text embeddings): MSE=0.2303, R2=0.0356, train_time=30.7492s, inference_time=0.0177s\n"
     ]
    }
   ],
   "source": [
    "best_rf = RandomForestRegressor(**best_params, random_state=42)\n",
    "results.append(train_and_evaluate(best_rf, \"RandomForest (text embeddings)\", X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2209f5a3",
   "metadata": {},
   "source": [
    "## RF: img embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f6cce6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_embeddings(image_folder_path):\n",
    "    model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
    "    model.eval()\n",
    "\n",
    "    image_embeddings = {}\n",
    "\n",
    "    for img_id in range(1, 18):\n",
    "        img_path = f\"{image_folder_path}/{img_id}.png\"\n",
    "        image = preprocess(Image.open(img_path)).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            embedding = model.encode_image(image)\n",
    "        image_embeddings[img_id] = embedding.cpu().numpy().flatten()\n",
    "\n",
    "    return image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cc797fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 01:50:47,057] A new study created in memory with name: no-name-ca450e7c-2e21-4e7e-9a89-a13aa2d21e57\n",
      "[I 2025-06-22 01:55:22,259] Trial 0 finished with value: 0.22201929532692533 and parameters: {'n_estimators': 287, 'max_depth': 5, 'min_samples_split': 29, 'min_samples_leaf': 16}. Best is trial 0 with value: 0.22201929532692533.\n",
      "[I 2025-06-22 01:55:59,924] Trial 1 finished with value: 0.22299963357261637 and parameters: {'n_estimators': 58, 'max_depth': 3, 'min_samples_split': 47, 'min_samples_leaf': 14}. Best is trial 0 with value: 0.22201929532692533.\n",
      "[I 2025-06-22 01:56:28,614] Trial 2 finished with value: 0.22192376185704615 and parameters: {'n_estimators': 31, 'max_depth': 5, 'min_samples_split': 21, 'min_samples_leaf': 29}. Best is trial 2 with value: 0.22192376185704615.\n",
      "[I 2025-06-22 01:58:05,680] Trial 3 finished with value: 0.22430267352122524 and parameters: {'n_estimators': 207, 'max_depth': 2, 'min_samples_split': 17, 'min_samples_leaf': 20}. Best is trial 2 with value: 0.22192376185704615.\n",
      "[I 2025-06-22 02:00:52,270] Trial 4 finished with value: 0.22288688634302117 and parameters: {'n_estimators': 253, 'max_depth': 3, 'min_samples_split': 60, 'min_samples_leaf': 29}. Best is trial 2 with value: 0.22192376185704615.\n",
      "[I 2025-06-22 02:01:24,109] Trial 5 finished with value: 0.22438219489834407 and parameters: {'n_estimators': 68, 'max_depth': 2, 'min_samples_split': 38, 'min_samples_leaf': 30}. Best is trial 2 with value: 0.22192376185704615.\n",
      "[I 2025-06-22 02:01:56,702] Trial 6 finished with value: 0.22226620418107004 and parameters: {'n_estimators': 35, 'max_depth': 5, 'min_samples_split': 42, 'min_samples_leaf': 15}. Best is trial 2 with value: 0.22192376185704615.\n",
      "[I 2025-06-22 02:02:37,600] Trial 7 finished with value: 0.2224038070147487 and parameters: {'n_estimators': 50, 'max_depth': 4, 'min_samples_split': 17, 'min_samples_leaf': 12}. Best is trial 2 with value: 0.22192376185704615.\n",
      "[I 2025-06-22 02:04:37,414] Trial 8 finished with value: 0.22290157452362833 and parameters: {'n_estimators': 183, 'max_depth': 3, 'min_samples_split': 53, 'min_samples_leaf': 25}. Best is trial 2 with value: 0.22192376185704615.\n",
      "[I 2025-06-22 02:08:29,531] Trial 9 finished with value: 0.222052269638027 and parameters: {'n_estimators': 288, 'max_depth': 4, 'min_samples_split': 22, 'min_samples_leaf': 25}. Best is trial 2 with value: 0.22192376185704615.\n",
      "[I 2025-06-22 02:10:12,413] Trial 10 finished with value: 0.22183102572508467 and parameters: {'n_estimators': 108, 'max_depth': 5, 'min_samples_split': 30, 'min_samples_leaf': 24}. Best is trial 10 with value: 0.22183102572508467.\n",
      "[I 2025-06-22 02:12:01,964] Trial 11 finished with value: 0.22180955307426262 and parameters: {'n_estimators': 115, 'max_depth': 5, 'min_samples_split': 30, 'min_samples_leaf': 25}. Best is trial 11 with value: 0.22180955307426262.\n",
      "[I 2025-06-22 02:13:40,152] Trial 12 finished with value: 0.2221424506823233 and parameters: {'n_estimators': 119, 'max_depth': 4, 'min_samples_split': 30, 'min_samples_leaf': 23}. Best is trial 11 with value: 0.22180955307426262.\n",
      "[I 2025-06-22 02:36:50,540] Trial 13 finished with value: 0.2218992494407412 and parameters: {'n_estimators': 119, 'max_depth': 5, 'min_samples_split': 30, 'min_samples_leaf': 21}. Best is trial 11 with value: 0.22180955307426262.\n",
      "[I 2025-06-22 02:47:09,774] Trial 14 finished with value: 0.22176444780422006 and parameters: {'n_estimators': 128, 'max_depth': 5, 'min_samples_split': 35, 'min_samples_leaf': 26}. Best is trial 14 with value: 0.22176444780422006.\n",
      "[I 2025-06-22 02:49:14,274] Trial 15 finished with value: 0.22203944010900384 and parameters: {'n_estimators': 155, 'max_depth': 4, 'min_samples_split': 35, 'min_samples_leaf': 27}. Best is trial 14 with value: 0.22176444780422006.\n",
      "[I 2025-06-22 02:51:41,638] Trial 16 finished with value: 0.22187902766820486 and parameters: {'n_estimators': 152, 'max_depth': 5, 'min_samples_split': 46, 'min_samples_leaf': 19}. Best is trial 14 with value: 0.22176444780422006.\n",
      "[I 2025-06-22 02:52:53,263] Trial 17 finished with value: 0.22208437206275516 and parameters: {'n_estimators': 88, 'max_depth': 4, 'min_samples_split': 36, 'min_samples_leaf': 27}. Best is trial 14 with value: 0.22176444780422006.\n",
      "[I 2025-06-22 02:56:09,642] Trial 18 finished with value: 0.221730900549059 and parameters: {'n_estimators': 203, 'max_depth': 5, 'min_samples_split': 25, 'min_samples_leaf': 27}. Best is trial 18 with value: 0.221730900549059.\n",
      "[I 2025-06-22 02:59:07,402] Trial 19 finished with value: 0.22209414136813765 and parameters: {'n_estimators': 212, 'max_depth': 4, 'min_samples_split': 24, 'min_samples_leaf': 22}. Best is trial 18 with value: 0.221730900549059.\n",
      "[I 2025-06-22 03:02:49,748] Trial 20 finished with value: 0.2217372075414171 and parameters: {'n_estimators': 225, 'max_depth': 5, 'min_samples_split': 24, 'min_samples_leaf': 27}. Best is trial 18 with value: 0.221730900549059.\n",
      "[I 2025-06-22 03:06:50,605] Trial 21 finished with value: 0.22172532973211148 and parameters: {'n_estimators': 243, 'max_depth': 5, 'min_samples_split': 25, 'min_samples_leaf': 27}. Best is trial 21 with value: 0.22172532973211148.\n",
      "[I 2025-06-22 03:10:55,239] Trial 22 finished with value: 0.22171003155028593 and parameters: {'n_estimators': 246, 'max_depth': 5, 'min_samples_split': 26, 'min_samples_leaf': 28}. Best is trial 22 with value: 0.22171003155028593.\n",
      "[I 2025-06-22 03:15:04,313] Trial 23 finished with value: 0.22169109107168414 and parameters: {'n_estimators': 252, 'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 30}. Best is trial 23 with value: 0.22169109107168414.\n",
      "[I 2025-06-22 03:18:38,295] Trial 24 finished with value: 0.2219882763583846 and parameters: {'n_estimators': 253, 'max_depth': 4, 'min_samples_split': 16, 'min_samples_leaf': 30}. Best is trial 23 with value: 0.22169109107168414.\n",
      "[I 2025-06-22 03:22:53,414] Trial 25 finished with value: 0.22168882662942208 and parameters: {'n_estimators': 253, 'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 29}. Best is trial 25 with value: 0.22168882662942208.\n",
      "[I 2025-06-22 03:26:48,755] Trial 26 finished with value: 0.22200571122935076 and parameters: {'n_estimators': 274, 'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 29}. Best is trial 25 with value: 0.22168882662942208.\n",
      "[I 2025-06-22 03:30:54,524] Trial 27 finished with value: 0.22213128898652004 and parameters: {'n_estimators': 234, 'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 10}. Best is trial 25 with value: 0.22168882662942208.\n",
      "[I 2025-06-22 03:34:03,507] Trial 28 finished with value: 0.22288565289887113 and parameters: {'n_estimators': 271, 'max_depth': 3, 'min_samples_split': 19, 'min_samples_leaf': 30}. Best is trial 25 with value: 0.22168882662942208.\n",
      "[I 2025-06-22 03:36:59,274] Trial 29 finished with value: 0.2219531346186053 and parameters: {'n_estimators': 172, 'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 18}. Best is trial 25 with value: 0.22168882662942208.\n",
      "[I 2025-06-22 03:41:33,267] Trial 30 finished with value: 0.22172048326271354 and parameters: {'n_estimators': 269, 'max_depth': 5, 'min_samples_split': 27, 'min_samples_leaf': 28}. Best is trial 25 with value: 0.22168882662942208.\n",
      "[I 2025-06-22 03:55:14,115] Trial 31 finished with value: 0.2217338272312091 and parameters: {'n_estimators': 294, 'max_depth': 5, 'min_samples_split': 27, 'min_samples_leaf': 28}. Best is trial 25 with value: 0.22168882662942208.\n",
      "[I 2025-06-22 04:28:13,882] Trial 32 finished with value: 0.2217231352988219 and parameters: {'n_estimators': 270, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 28}. Best is trial 25 with value: 0.22168882662942208.\n",
      "[I 2025-06-22 04:33:02,932] Trial 33 finished with value: 0.2217172822351233 and parameters: {'n_estimators': 299, 'max_depth': 5, 'min_samples_split': 27, 'min_samples_leaf': 29}. Best is trial 25 with value: 0.22168882662942208.\n",
      "[I 2025-06-22 04:37:55,734] Trial 34 finished with value: 0.22171601681219527 and parameters: {'n_estimators': 296, 'max_depth': 5, 'min_samples_split': 22, 'min_samples_leaf': 30}. Best is trial 25 with value: 0.22168882662942208.\n",
      "[I 2025-06-22 04:40:00,595] Trial 35 finished with value: 0.22423355497781555 and parameters: {'n_estimators': 249, 'max_depth': 2, 'min_samples_split': 22, 'min_samples_leaf': 30}. Best is trial 25 with value: 0.22168882662942208.\n",
      "[I 2025-06-22 04:43:15,753] Trial 36 finished with value: 0.22198962594358274 and parameters: {'n_estimators': 226, 'max_depth': 4, 'min_samples_split': 19, 'min_samples_leaf': 30}. Best is trial 25 with value: 0.22168882662942208.\n",
      "[I 2025-06-22 04:46:26,122] Trial 37 finished with value: 0.22168053609881114 and parameters: {'n_estimators': 189, 'max_depth': 5, 'min_samples_split': 21, 'min_samples_leaf': 29}. Best is trial 37 with value: 0.22168053609881114.\n",
      "[I 2025-06-22 04:49:46,554] Trial 38 finished with value: 0.22201299365596056 and parameters: {'n_estimators': 193, 'max_depth': 5, 'min_samples_split': 33, 'min_samples_leaf': 17}. Best is trial 37 with value: 0.22168053609881114.\n",
      "[I 2025-06-22 04:53:30,318] Trial 39 finished with value: 0.22177102941166416 and parameters: {'n_estimators': 219, 'max_depth': 5, 'min_samples_split': 18, 'min_samples_leaf': 26}. Best is trial 37 with value: 0.22168053609881114.\n",
      "[I 2025-06-22 04:56:08,205] Trial 40 finished with value: 0.222023544176714 and parameters: {'n_estimators': 177, 'max_depth': 4, 'min_samples_split': 60, 'min_samples_leaf': 24}. Best is trial 37 with value: 0.22168053609881114.\n",
      "[I 2025-06-22 05:00:50,926] Trial 41 finished with value: 0.22169696795067825 and parameters: {'n_estimators': 264, 'max_depth': 5, 'min_samples_split': 22, 'min_samples_leaf': 29}. Best is trial 37 with value: 0.22168053609881114.\n",
      "[I 2025-06-22 05:04:58,296] Trial 42 finished with value: 0.22170188980578281 and parameters: {'n_estimators': 239, 'max_depth': 5, 'min_samples_split': 21, 'min_samples_leaf': 29}. Best is trial 37 with value: 0.22168053609881114.\n",
      "[I 2025-06-22 05:09:35,298] Trial 43 finished with value: 0.2216893287081418 and parameters: {'n_estimators': 263, 'max_depth': 5, 'min_samples_split': 21, 'min_samples_leaf': 29}. Best is trial 37 with value: 0.22168053609881114.\n",
      "[I 2025-06-22 05:14:33,639] Trial 44 finished with value: 0.22177559990997509 and parameters: {'n_estimators': 285, 'max_depth': 5, 'min_samples_split': 17, 'min_samples_leaf': 26}. Best is trial 37 with value: 0.22168053609881114.\n",
      "[I 2025-06-22 05:17:40,425] Trial 45 finished with value: 0.222889216971995 and parameters: {'n_estimators': 260, 'max_depth': 3, 'min_samples_split': 54, 'min_samples_leaf': 29}. Best is trial 37 with value: 0.22168053609881114.\n",
      "[I 2025-06-22 05:22:34,188] Trial 46 finished with value: 0.22173678951692755 and parameters: {'n_estimators': 280, 'max_depth': 5, 'min_samples_split': 23, 'min_samples_leaf': 28}. Best is trial 37 with value: 0.22168053609881114.\n",
      "[I 2025-06-22 05:24:18,321] Trial 47 finished with value: 0.22428441170225258 and parameters: {'n_estimators': 198, 'max_depth': 2, 'min_samples_split': 17, 'min_samples_leaf': 14}. Best is trial 37 with value: 0.22168053609881114.\n",
      "[I 2025-06-22 05:45:16,339] Trial 48 finished with value: 0.2217510156135929 and parameters: {'n_estimators': 260, 'max_depth': 5, 'min_samples_split': 40, 'min_samples_leaf': 25}. Best is trial 37 with value: 0.22168053609881114.\n",
      "[I 2025-06-22 05:56:45,719] Trial 49 finished with value: 0.2220566819858687 and parameters: {'n_estimators': 232, 'max_depth': 4, 'min_samples_split': 32, 'min_samples_leaf': 24}. Best is trial 37 with value: 0.22168053609881114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 189, 'max_depth': 5, 'min_samples_split': 21, 'min_samples_leaf': 29}\n",
      "Best CV MSE: 0.22168053609881114\n"
     ]
    }
   ],
   "source": [
    "image_embeddings = create_image_embeddings('../images')\n",
    "\n",
    "cat_columns = ['gender', 'education', 'income', 'marital_status']\n",
    "num_columns = ['age']\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_features(\n",
    "    profiles, image_embeddings, num_columns, cat_columns, target_column=target\n",
    ")\n",
    "\n",
    "best_params = optimize_rf_with_optuna(X_train, y_train, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0fbfd39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest (img embeddings): MSE=0.2303, R2=0.0356, train_time=46.5691s, inference_time=0.0241s\n"
     ]
    }
   ],
   "source": [
    "best_rf = RandomForestRegressor(**best_params, random_state=42)\n",
    "results.append(train_and_evaluate(best_rf, \"RandomForest (img embeddings)\", X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3486577",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437bf38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7fd19018",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def create_text_embeddings(description_mapping):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        text_embeddings = {k: model.encode(v, normalize_embeddings=True) for k, v in description_mapping.items()}\n",
    "    return text_embeddings\n",
    "\n",
    "\n",
    "def create_image_embeddings(image_folder_path):\n",
    "    model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    image_embeddings = {}\n",
    "\n",
    "    for img_id in range(1, 18):\n",
    "        img_path = f\"{image_folder_path}/{img_id}.png\"\n",
    "        image = preprocess(Image.open(img_path)).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            embedding = model.encode_image(image)\n",
    "            embedding /= embedding.norm(dim=-1, keepdim=True)  # Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ\n",
    "        image_embeddings[img_id] = embedding.cpu().numpy().flatten()\n",
    "\n",
    "    return image_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bc13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a539e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPRegressor(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dims=[256, 64], dropout=0.2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        for h in hidden_dims:\n",
    "            layers += [\n",
    "                nn.Linear(prev, h),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ]\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, 1))\n",
    "        layers.append(nn.Tanh())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "13ce437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_mlp(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    model_name=\"MLPRegressor\", hidden_dims=[256,64],\n",
    "    n_epochs=20, lr=1e-3, batch_size=32\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_ds = MyDataset(X_train, y_train)\n",
    "    test_ds  = MyDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "    model = MLPRegressor(input_dim=X_train.shape[1], hidden_dims=hidden_dims).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    start_train = time.time()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} - Train Loss: {np.mean(losses):.4f}\")\n",
    "        \n",
    "    train_time = time.time() - start_train\n",
    "\n",
    "    model.eval()\n",
    "    y_preds, y_true = [], []\n",
    "    start_inf = time.time()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb = xb.to(device)\n",
    "            out = model(xb).cpu().numpy().flatten()\n",
    "            y_preds.extend(out)\n",
    "            y_true.extend(yb.numpy().flatten())\n",
    "    inf_time = time.time() - start_inf\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_preds)\n",
    "    r2  = r2_score(y_true, y_preds)\n",
    "\n",
    "    print(f\"{model_name}: MSE={mse:.4f}, R2={r2:.4f}, train_time={train_time:.2f}s, inference_time={inf_time:.2f}s\")\n",
    "\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'mse': mse,\n",
    "        'r2': r2,\n",
    "        'train_time': train_time,\n",
    "        'inference_time': inf_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0c3c57",
   "metadata": {},
   "source": [
    "## MLP: text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e192a9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55 - Train Loss: 0.2328\n",
      "Epoch 2/55 - Train Loss: 0.2253\n",
      "Epoch 3/55 - Train Loss: 0.2240\n",
      "Epoch 4/55 - Train Loss: 0.2217\n",
      "Epoch 5/55 - Train Loss: 0.2226\n",
      "Epoch 6/55 - Train Loss: 0.2215\n",
      "Epoch 7/55 - Train Loss: 0.2216\n",
      "Epoch 8/55 - Train Loss: 0.2206\n",
      "Epoch 9/55 - Train Loss: 0.2207\n",
      "Epoch 10/55 - Train Loss: 0.2201\n",
      "Epoch 11/55 - Train Loss: 0.2214\n",
      "Epoch 12/55 - Train Loss: 0.2204\n",
      "Epoch 13/55 - Train Loss: 0.2201\n",
      "Epoch 14/55 - Train Loss: 0.2197\n",
      "Epoch 15/55 - Train Loss: 0.2197\n",
      "Epoch 16/55 - Train Loss: 0.2199\n",
      "Epoch 17/55 - Train Loss: 0.2199\n",
      "Epoch 18/55 - Train Loss: 0.2198\n",
      "Epoch 19/55 - Train Loss: 0.2187\n",
      "Epoch 20/55 - Train Loss: 0.2191\n",
      "Epoch 21/55 - Train Loss: 0.2182\n",
      "Epoch 22/55 - Train Loss: 0.2193\n",
      "Epoch 23/55 - Train Loss: 0.2188\n",
      "Epoch 24/55 - Train Loss: 0.2183\n",
      "Epoch 25/55 - Train Loss: 0.2186\n",
      "Epoch 26/55 - Train Loss: 0.2182\n",
      "Epoch 27/55 - Train Loss: 0.2185\n",
      "Epoch 28/55 - Train Loss: 0.2178\n",
      "Epoch 29/55 - Train Loss: 0.2182\n",
      "Epoch 30/55 - Train Loss: 0.2180\n",
      "Epoch 31/55 - Train Loss: 0.2171\n",
      "Epoch 32/55 - Train Loss: 0.2172\n",
      "Epoch 33/55 - Train Loss: 0.2174\n",
      "Epoch 34/55 - Train Loss: 0.2169\n",
      "Epoch 35/55 - Train Loss: 0.2169\n",
      "Epoch 36/55 - Train Loss: 0.2171\n",
      "Epoch 37/55 - Train Loss: 0.2172\n",
      "Epoch 38/55 - Train Loss: 0.2169\n",
      "Epoch 39/55 - Train Loss: 0.2167\n",
      "Epoch 40/55 - Train Loss: 0.2164\n",
      "Epoch 41/55 - Train Loss: 0.2166\n",
      "Epoch 42/55 - Train Loss: 0.2161\n",
      "Epoch 43/55 - Train Loss: 0.2165\n",
      "Epoch 44/55 - Train Loss: 0.2160\n",
      "Epoch 45/55 - Train Loss: 0.2160\n",
      "Epoch 46/55 - Train Loss: 0.2157\n",
      "Epoch 47/55 - Train Loss: 0.2159\n",
      "Epoch 48/55 - Train Loss: 0.2153\n",
      "Epoch 49/55 - Train Loss: 0.2158\n",
      "Epoch 50/55 - Train Loss: 0.2155\n",
      "Epoch 51/55 - Train Loss: 0.2145\n",
      "Epoch 52/55 - Train Loss: 0.2153\n",
      "Epoch 53/55 - Train Loss: 0.2153\n",
      "Epoch 54/55 - Train Loss: 0.2148\n",
      "Epoch 55/55 - Train Loss: 0.2150\n",
      "MLP on text+socdem: MSE=0.2285, R2=0.0434, train_time=17.20s, inference_time=0.01s\n"
     ]
    }
   ],
   "source": [
    "set_seed(17)\n",
    "\n",
    "text_embeddings = create_text_embeddings(description_mapping)\n",
    "\n",
    "cat_columns = ['gender', 'education', 'income', 'marital_status']\n",
    "num_columns = ['age']\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_features(\n",
    "    profiles, text_embeddings, num_columns, cat_columns, target\n",
    ")\n",
    "\n",
    "result = train_and_evaluate_mlp(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    model_name=\"MLP on text+socdem\",\n",
    "    hidden_dims=[512, 128],\n",
    "    n_epochs=55,\n",
    "    lr=1e-3,\n",
    "    batch_size=64\n",
    ")\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd0c72",
   "metadata": {},
   "source": [
    "## MLP: img embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f5e7f29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.2319\n",
      "Epoch 2/50 - Train Loss: 0.2264\n",
      "Epoch 3/50 - Train Loss: 0.2239\n",
      "Epoch 4/50 - Train Loss: 0.2241\n",
      "Epoch 5/50 - Train Loss: 0.2225\n",
      "Epoch 6/50 - Train Loss: 0.2219\n",
      "Epoch 7/50 - Train Loss: 0.2221\n",
      "Epoch 8/50 - Train Loss: 0.2215\n",
      "Epoch 9/50 - Train Loss: 0.2214\n",
      "Epoch 10/50 - Train Loss: 0.2206\n",
      "Epoch 11/50 - Train Loss: 0.2212\n",
      "Epoch 12/50 - Train Loss: 0.2202\n",
      "Epoch 13/50 - Train Loss: 0.2206\n",
      "Epoch 14/50 - Train Loss: 0.2197\n",
      "Epoch 15/50 - Train Loss: 0.2194\n",
      "Epoch 16/50 - Train Loss: 0.2201\n",
      "Epoch 17/50 - Train Loss: 0.2199\n",
      "Epoch 18/50 - Train Loss: 0.2193\n",
      "Epoch 19/50 - Train Loss: 0.2188\n",
      "Epoch 20/50 - Train Loss: 0.2187\n",
      "Epoch 21/50 - Train Loss: 0.2187\n",
      "Epoch 22/50 - Train Loss: 0.2188\n",
      "Epoch 23/50 - Train Loss: 0.2185\n",
      "Epoch 24/50 - Train Loss: 0.2194\n",
      "Epoch 25/50 - Train Loss: 0.2189\n",
      "Epoch 26/50 - Train Loss: 0.2175\n",
      "Epoch 27/50 - Train Loss: 0.2193\n",
      "Epoch 28/50 - Train Loss: 0.2187\n",
      "Epoch 29/50 - Train Loss: 0.2186\n",
      "Epoch 30/50 - Train Loss: 0.2183\n",
      "Epoch 31/50 - Train Loss: 0.2181\n",
      "Epoch 32/50 - Train Loss: 0.2184\n",
      "Epoch 33/50 - Train Loss: 0.2178\n",
      "Epoch 34/50 - Train Loss: 0.2183\n",
      "Epoch 35/50 - Train Loss: 0.2181\n",
      "Epoch 36/50 - Train Loss: 0.2176\n",
      "Epoch 37/50 - Train Loss: 0.2171\n",
      "Epoch 38/50 - Train Loss: 0.2168\n",
      "Epoch 39/50 - Train Loss: 0.2159\n",
      "Epoch 40/50 - Train Loss: 0.2173\n",
      "Epoch 41/50 - Train Loss: 0.2171\n",
      "Epoch 42/50 - Train Loss: 0.2171\n",
      "Epoch 43/50 - Train Loss: 0.2163\n",
      "Epoch 44/50 - Train Loss: 0.2178\n",
      "Epoch 45/50 - Train Loss: 0.2162\n",
      "Epoch 46/50 - Train Loss: 0.2165\n",
      "Epoch 47/50 - Train Loss: 0.2163\n",
      "Epoch 48/50 - Train Loss: 0.2165\n",
      "Epoch 49/50 - Train Loss: 0.2171\n",
      "Epoch 50/50 - Train Loss: 0.2158\n",
      "MLP on img+socdem: MSE=0.2293, R2=0.0400, train_time=23.87s, inference_time=0.02s\n"
     ]
    }
   ],
   "source": [
    "set_seed(17)\n",
    "\n",
    "image_embeddings = create_image_embeddings('../images')\n",
    "\n",
    "cat_columns = ['gender', 'education', 'income', 'marital_status']\n",
    "num_columns = ['age']\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_features(\n",
    "    profiles, image_embeddings, num_columns, cat_columns, target\n",
    ")\n",
    "\n",
    "result = train_and_evaluate_mlp(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    model_name=\"MLP on img+socdem\",\n",
    "    hidden_dims=[512, 128],\n",
    "    n_epochs=50,\n",
    "    lr=1e-3,\n",
    "    batch_size=64\n",
    ")\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff61ed13",
   "metadata": {},
   "source": [
    "## Clusterization + MLP: text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "52491e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(X_train, y_train, input_dim, hidden_dims=[512, 128], lr=1e-3, batch_size=64, n_epochs=25):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_ds = MyDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = MLPRegressor(input_dim=input_dim, hidden_dims=hidden_dims).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} - Loss: {np.mean(losses):.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "32674f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp_with_clustering(profiles, description_mapping, target):\n",
    "    start_train = time.time()\n",
    "\n",
    "    text_embeddings = create_text_embeddings(description_mapping)\n",
    "    cat_columns = ['gender', 'education', 'income', 'marital_status']\n",
    "    num_columns = ['age']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = prepare_features(\n",
    "        profiles, text_embeddings, num_columns, cat_columns, target_column=target\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    embedding_dim = list(text_embeddings.values())[0].shape[0] * 3\n",
    "    socdem_start = embedding_dim\n",
    "    socdem_end = embedding_dim + len(num_columns) + len(cat_columns)\n",
    "    X_socdem_train = X_train_scaled[:, socdem_start:socdem_end]\n",
    "\n",
    "    n_clusters = 3\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=17)\n",
    "    cluster_train = kmeans.fit_predict(X_socdem_train)\n",
    "\n",
    "    mlp_models = {}\n",
    "\n",
    "    for cluster_id in range(n_clusters):\n",
    "        idx = np.where(cluster_train == cluster_id)[0]\n",
    "        X_cluster = X_train_scaled[idx]\n",
    "        y_cluster = y_train[idx]\n",
    "\n",
    "        print(f\"\\nÐžÐ±ÑƒÑ‡Ð°ÐµÐ¼ MLP Ð´Ð»Ñ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð° {cluster_id}, Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð²: {len(idx)}\")\n",
    "        model = train_mlp(\n",
    "            X_cluster, y_cluster,\n",
    "            input_dim=X_train.shape[1],\n",
    "            hidden_dims=[512, 128],\n",
    "            lr=1e-3, batch_size=64, n_epochs=10\n",
    "        )\n",
    "        mlp_models[cluster_id] = model\n",
    "\n",
    "    joblib.dump(scaler, 'scaler.pkl')\n",
    "    joblib.dump(kmeans, 'kmeans.pkl')\n",
    "\n",
    "    for cluster_id, model in mlp_models.items():\n",
    "        torch.save(model.state_dict(), f'mlp_model_cluster_{cluster_id}.pth')\n",
    "\n",
    "    end_train = time.time()\n",
    "    train_time = end_train - start_train\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    y_preds = []\n",
    "    y_true = []\n",
    "\n",
    "    start_inference = time.time()\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        x_sample = X_test_scaled[i].reshape(1, -1)\n",
    "        socdem_sample = x_sample[:, socdem_start:socdem_end]\n",
    "        cluster_id = kmeans.predict(socdem_sample)[0]\n",
    "\n",
    "        model = MLPRegressor(input_dim=X_train.shape[1], hidden_dims=[512, 128])\n",
    "        model.load_state_dict(torch.load(f'mlp_model_cluster_{cluster_id}.pth'))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        x_tensor = torch.tensor(x_sample, dtype=torch.float32).to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(x_tensor).cpu().numpy().flatten()[0]\n",
    "\n",
    "        y_preds.append(pred)\n",
    "        y_true.append(y_test[i])\n",
    "\n",
    "    end_inference = time.time()\n",
    "    inference_time = end_inference - start_inference\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_preds)\n",
    "    r2 = r2_score(y_true, y_preds)\n",
    "\n",
    "    print(f\"\\nFinal evaluation: MSE={mse:.4f}, R2={r2:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'model_name': 'MLP with clustering on socdem',\n",
    "        'mse': mse,\n",
    "        'r2': r2,\n",
    "        'train_time': train_time,\n",
    "        'inference_time': inference_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3dd44ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ÐžÐ±ÑƒÑ‡Ð°ÐµÐ¼ MLP Ð´Ð»Ñ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð° 0, Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð²: 3014\n",
      "Epoch 1/10 - Loss: 0.2497\n",
      "Epoch 2/10 - Loss: 0.2257\n",
      "Epoch 3/10 - Loss: 0.2188\n",
      "Epoch 4/10 - Loss: 0.2176\n",
      "Epoch 5/10 - Loss: 0.2191\n",
      "Epoch 6/10 - Loss: 0.2162\n",
      "Epoch 7/10 - Loss: 0.2185\n",
      "Epoch 8/10 - Loss: 0.2155\n",
      "Epoch 9/10 - Loss: 0.2187\n",
      "Epoch 10/10 - Loss: 0.2176\n",
      "\n",
      "ÐžÐ±ÑƒÑ‡Ð°ÐµÐ¼ MLP Ð´Ð»Ñ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð° 1, Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð²: 2449\n",
      "Epoch 1/10 - Loss: 0.2521\n",
      "Epoch 2/10 - Loss: 0.2191\n",
      "Epoch 3/10 - Loss: 0.2171\n",
      "Epoch 4/10 - Loss: 0.2130\n",
      "Epoch 5/10 - Loss: 0.2125\n",
      "Epoch 6/10 - Loss: 0.2112\n",
      "Epoch 7/10 - Loss: 0.2088\n",
      "Epoch 8/10 - Loss: 0.2130\n",
      "Epoch 9/10 - Loss: 0.2080\n",
      "Epoch 10/10 - Loss: 0.2065\n",
      "\n",
      "ÐžÐ±ÑƒÑ‡Ð°ÐµÐ¼ MLP Ð´Ð»Ñ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð° 2, Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð²: 2530\n",
      "Epoch 1/10 - Loss: 0.2735\n",
      "Epoch 2/10 - Loss: 0.2439\n",
      "Epoch 3/10 - Loss: 0.2355\n",
      "Epoch 4/10 - Loss: 0.2369\n",
      "Epoch 5/10 - Loss: 0.2337\n",
      "Epoch 6/10 - Loss: 0.2335\n",
      "Epoch 7/10 - Loss: 0.2341\n",
      "Epoch 8/10 - Loss: 0.2322\n",
      "Epoch 9/10 - Loss: 0.2312\n",
      "Epoch 10/10 - Loss: 0.2316\n",
      "\n",
      "Final evaluation: MSE=0.2298, R2=0.0378\n"
     ]
    }
   ],
   "source": [
    "set_seed(17)\n",
    "\n",
    "results.append(train_mlp_with_clustering(profiles, description_mapping, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6619edf9",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9785bd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_84379_row0_col1 {\n",
       "  background-color: #b55e6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_84379_row0_col2 {\n",
       "  background-color: #d17c7d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_84379_row0_col3, #T_84379_row0_col4, #T_84379_row1_col4, #T_84379_row2_col4, #T_84379_row3_col4, #T_84379_row4_col4, #T_84379_row5_col4, #T_84379_row6_col4, #T_84379_row7_col1, #T_84379_row7_col2, #T_84379_row7_col4, #T_84379_row8_col4 {\n",
       "  background-color: #3c775b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_84379_row1_col1, #T_84379_row1_col2, #T_84379_row6_col3, #T_84379_row9_col4 {\n",
       "  background-color: #ae576b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_84379_row1_col3, #T_84379_row4_col3 {\n",
       "  background-color: #3d795c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_84379_row2_col1, #T_84379_row2_col2 {\n",
       "  background-color: #e0edba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_84379_row2_col3 {\n",
       "  background-color: #3e7a5e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_84379_row3_col1, #T_84379_row3_col2 {\n",
       "  background-color: #d5e7b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_84379_row3_col3 {\n",
       "  background-color: #407c5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_84379_row4_col1, #T_84379_row4_col2 {\n",
       "  background-color: #d4e7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_84379_row5_col1, #T_84379_row5_col2, #T_84379_row6_col1, #T_84379_row6_col2 {\n",
       "  background-color: #98c596;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_84379_row5_col3 {\n",
       "  background-color: #fedfb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_84379_row7_col3 {\n",
       "  background-color: #f6fad3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_84379_row8_col1, #T_84379_row8_col2 {\n",
       "  background-color: #69a880;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_84379_row8_col3 {\n",
       "  background-color: #fffddb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_84379_row9_col1, #T_84379_row9_col2 {\n",
       "  background-color: #81b78b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_84379_row9_col3 {\n",
       "  background-color: #74af85;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_84379\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_84379_level0_col0\" class=\"col_heading level0 col0\" >model_name</th>\n",
       "      <th id=\"T_84379_level0_col1\" class=\"col_heading level0 col1\" >mse</th>\n",
       "      <th id=\"T_84379_level0_col2\" class=\"col_heading level0 col2\" >r2</th>\n",
       "      <th id=\"T_84379_level0_col3\" class=\"col_heading level0 col3\" >train_time</th>\n",
       "      <th id=\"T_84379_level0_col4\" class=\"col_heading level0 col4\" >inference_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_84379_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_84379_row0_col0\" class=\"data row0 col0\" >Baseline (mean prediction)</td>\n",
       "      <td id=\"T_84379_row0_col1\" class=\"data row0 col1\" >0.2395</td>\n",
       "      <td id=\"T_84379_row0_col2\" class=\"data row0 col2\" >0.0000</td>\n",
       "      <td id=\"T_84379_row0_col3\" class=\"data row0 col3\" >0.0011</td>\n",
       "      <td id=\"T_84379_row0_col4\" class=\"data row0 col4\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84379_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_84379_row1_col0\" class=\"data row1 col0\" >RandomForest (socdem only)</td>\n",
       "      <td id=\"T_84379_row1_col1\" class=\"data row1 col1\" >0.2397</td>\n",
       "      <td id=\"T_84379_row1_col2\" class=\"data row1 col2\" >-0.0039</td>\n",
       "      <td id=\"T_84379_row1_col3\" class=\"data row1 col3\" >0.3062</td>\n",
       "      <td id=\"T_84379_row1_col4\" class=\"data row1 col4\" >0.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84379_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_84379_row2_col0\" class=\"data row2 col0\" >RandomForest (socdem + weighted meta)</td>\n",
       "      <td id=\"T_84379_row2_col1\" class=\"data row2 col1\" >0.2325</td>\n",
       "      <td id=\"T_84379_row2_col2\" class=\"data row2 col2\" >0.0266</td>\n",
       "      <td id=\"T_84379_row2_col3\" class=\"data row2 col3\" >0.5402</td>\n",
       "      <td id=\"T_84379_row2_col4\" class=\"data row2 col4\" >0.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84379_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_84379_row3_col0\" class=\"data row3 col0\" >RandomForest (socdem + one-hot meta)</td>\n",
       "      <td id=\"T_84379_row3_col1\" class=\"data row3 col1\" >0.2320</td>\n",
       "      <td id=\"T_84379_row3_col2\" class=\"data row3 col2\" >0.0284</td>\n",
       "      <td id=\"T_84379_row3_col3\" class=\"data row3 col3\" >0.7132</td>\n",
       "      <td id=\"T_84379_row3_col4\" class=\"data row3 col4\" >0.0161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84379_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_84379_row4_col0\" class=\"data row4 col0\" >RandomForest (meta only)</td>\n",
       "      <td id=\"T_84379_row4_col1\" class=\"data row4 col1\" >0.2320</td>\n",
       "      <td id=\"T_84379_row4_col2\" class=\"data row4 col2\" >0.0284</td>\n",
       "      <td id=\"T_84379_row4_col3\" class=\"data row4 col3\" >0.3075</td>\n",
       "      <td id=\"T_84379_row4_col4\" class=\"data row4 col4\" >0.0137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84379_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_84379_row5_col0\" class=\"data row5 col0\" >RandomForest (text embeddings)</td>\n",
       "      <td id=\"T_84379_row5_col1\" class=\"data row5 col1\" >0.2303</td>\n",
       "      <td id=\"T_84379_row5_col2\" class=\"data row5 col2\" >0.0356</td>\n",
       "      <td id=\"T_84379_row5_col3\" class=\"data row5 col3\" >30.7492</td>\n",
       "      <td id=\"T_84379_row5_col4\" class=\"data row5 col4\" >0.0177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84379_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_84379_row6_col0\" class=\"data row6 col0\" >RandomForest (img embeddings)</td>\n",
       "      <td id=\"T_84379_row6_col1\" class=\"data row6 col1\" >0.2303</td>\n",
       "      <td id=\"T_84379_row6_col2\" class=\"data row6 col2\" >0.0356</td>\n",
       "      <td id=\"T_84379_row6_col3\" class=\"data row6 col3\" >46.5691</td>\n",
       "      <td id=\"T_84379_row6_col4\" class=\"data row6 col4\" >0.0241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84379_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_84379_row7_col0\" class=\"data row7 col0\" >MLP on text+socdem</td>\n",
       "      <td id=\"T_84379_row7_col1\" class=\"data row7 col1\" >0.2279</td>\n",
       "      <td id=\"T_84379_row7_col2\" class=\"data row7 col2\" >0.0459</td>\n",
       "      <td id=\"T_84379_row7_col3\" class=\"data row7 col3\" >21.5193</td>\n",
       "      <td id=\"T_84379_row7_col4\" class=\"data row7 col4\" >0.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84379_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_84379_row8_col0\" class=\"data row8 col0\" >MLP on img+socdem</td>\n",
       "      <td id=\"T_84379_row8_col1\" class=\"data row8 col1\" >0.2293</td>\n",
       "      <td id=\"T_84379_row8_col2\" class=\"data row8 col2\" >0.0400</td>\n",
       "      <td id=\"T_84379_row8_col3\" class=\"data row8 col3\" >23.8672</td>\n",
       "      <td id=\"T_84379_row8_col4\" class=\"data row8 col4\" >0.0189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84379_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_84379_row9_col0\" class=\"data row9 col0\" >MLP with clustering on socdem</td>\n",
       "      <td id=\"T_84379_row9_col1\" class=\"data row9 col1\" >0.2298</td>\n",
       "      <td id=\"T_84379_row9_col2\" class=\"data row9 col2\" >0.0378</td>\n",
       "      <td id=\"T_84379_row9_col3\" class=\"data row9 col3\" >6.4228</td>\n",
       "      <td id=\"T_84379_row9_col4\" class=\"data row9 col4\" >7.3422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14a8caf00>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "cols = ['model_name'] + [col for col in df_results.columns if col != 'model_name']\n",
    "df_results = df_results[cols]\n",
    "\n",
    "format_dict = {\n",
    "    'mse': \"{:.4f}\",\n",
    "    'r2': \"{:.4f}\",\n",
    "    'train_time': \"{:.4f}\",\n",
    "    'inference_time': \"{:.4f}\"\n",
    "}\n",
    "\n",
    "def make_pastel_cmap(base_cmap_name, n_colors=256, alpha=0.5):\n",
    "    base = plt.get_cmap(base_cmap_name, n_colors)\n",
    "    colors = base(np.linspace(0, 1, n_colors))\n",
    "    from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
    "    hsv_colors = rgb_to_hsv(colors[:, :3])\n",
    "    hsv_colors[:, 1] = hsv_colors[:, 1] * alpha\n",
    "    hsv_colors[:, 2] = hsv_colors[:, 2] + (1 - hsv_colors[:, 2]) * 0.1\n",
    "    new_rgb = hsv_to_rgb(hsv_colors)\n",
    "    colors[:, :3] = new_rgb\n",
    "    return LinearSegmentedColormap.from_list(f\"pastel_{base_cmap_name}\", colors)\n",
    "\n",
    "pastel_rdylgn = make_pastel_cmap('RdYlGn')\n",
    "pastel_rdylgn_r = make_pastel_cmap('RdYlGn_r')\n",
    "\n",
    "styled = df_results.style.format(format_dict)\n",
    "\n",
    "styled = styled.background_gradient(subset=['mse'], cmap=pastel_rdylgn_r)\n",
    "styled = styled.background_gradient(subset=['r2'], cmap=pastel_rdylgn)\n",
    "styled = styled.background_gradient(subset=['train_time', 'inference_time'], cmap=pastel_rdylgn_r)\n",
    "\n",
    "styled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd42606",
   "metadata": {},
   "source": [
    "# Inference preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0ffbba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "embeddings = {}\n",
    "for img_id, description in description_mapping.items():\n",
    "    embeddings[img_id] = model.encode(description)\n",
    "\n",
    "with open(\"../inference/embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "cb85f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 - Train Loss: 0.2363\n",
      "Epoch 2/60 - Train Loss: 0.2272\n",
      "Epoch 3/60 - Train Loss: 0.2256\n",
      "Epoch 4/60 - Train Loss: 0.2260\n",
      "Epoch 5/60 - Train Loss: 0.2229\n",
      "Epoch 6/60 - Train Loss: 0.2234\n",
      "Epoch 7/60 - Train Loss: 0.2222\n",
      "Epoch 8/60 - Train Loss: 0.2233\n",
      "Epoch 9/60 - Train Loss: 0.2232\n",
      "Epoch 10/60 - Train Loss: 0.2213\n",
      "Epoch 11/60 - Train Loss: 0.2210\n",
      "Epoch 12/60 - Train Loss: 0.2214\n",
      "Epoch 13/60 - Train Loss: 0.2238\n",
      "Epoch 14/60 - Train Loss: 0.2208\n",
      "Epoch 15/60 - Train Loss: 0.2213\n",
      "Epoch 16/60 - Train Loss: 0.2223\n",
      "Epoch 17/60 - Train Loss: 0.2219\n",
      "Epoch 18/60 - Train Loss: 0.2222\n",
      "Epoch 19/60 - Train Loss: 0.2205\n",
      "Epoch 20/60 - Train Loss: 0.2200\n",
      "Epoch 21/60 - Train Loss: 0.2202\n",
      "Epoch 22/60 - Train Loss: 0.2202\n",
      "Epoch 23/60 - Train Loss: 0.2189\n",
      "Epoch 24/60 - Train Loss: 0.2205\n",
      "Epoch 25/60 - Train Loss: 0.2195\n",
      "Epoch 26/60 - Train Loss: 0.2197\n",
      "Epoch 27/60 - Train Loss: 0.2203\n",
      "Epoch 28/60 - Train Loss: 0.2186\n",
      "Epoch 29/60 - Train Loss: 0.2189\n",
      "Epoch 30/60 - Train Loss: 0.2179\n",
      "Epoch 31/60 - Train Loss: 0.2179\n",
      "Epoch 32/60 - Train Loss: 0.2179\n",
      "Epoch 33/60 - Train Loss: 0.2178\n",
      "Epoch 34/60 - Train Loss: 0.2184\n",
      "Epoch 35/60 - Train Loss: 0.2173\n",
      "Epoch 36/60 - Train Loss: 0.2174\n",
      "Epoch 37/60 - Train Loss: 0.2172\n",
      "Epoch 38/60 - Train Loss: 0.2179\n",
      "Epoch 39/60 - Train Loss: 0.2181\n",
      "Epoch 40/60 - Train Loss: 0.2181\n",
      "Epoch 41/60 - Train Loss: 0.2166\n",
      "Epoch 42/60 - Train Loss: 0.2152\n",
      "Epoch 43/60 - Train Loss: 0.2177\n",
      "Epoch 44/60 - Train Loss: 0.2159\n",
      "Epoch 45/60 - Train Loss: 0.2161\n",
      "Epoch 46/60 - Train Loss: 0.2170\n",
      "Epoch 47/60 - Train Loss: 0.2162\n",
      "Epoch 48/60 - Train Loss: 0.2159\n",
      "Epoch 49/60 - Train Loss: 0.2166\n",
      "Epoch 50/60 - Train Loss: 0.2170\n",
      "Epoch 51/60 - Train Loss: 0.2150\n",
      "Epoch 52/60 - Train Loss: 0.2157\n",
      "Epoch 53/60 - Train Loss: 0.2154\n",
      "Epoch 54/60 - Train Loss: 0.2147\n",
      "Epoch 55/60 - Train Loss: 0.2143\n",
      "Epoch 56/60 - Train Loss: 0.2179\n",
      "Epoch 57/60 - Train Loss: 0.2158\n",
      "Epoch 58/60 - Train Loss: 0.2157\n",
      "Epoch 59/60 - Train Loss: 0.2131\n",
      "Epoch 60/60 - Train Loss: 0.2155\n",
      "ÐœÐ¾Ð´ÐµÐ»ÑŒ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð° Ð² ../inference/mlp_model.pth\n"
     ]
    }
   ],
   "source": [
    "def train_mlp_and_save(X, y, hidden_dims=[512, 128], n_epochs=60, lr=1e-3, batch_size=64, save_path=\"mlp_model.pth\"):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_ds = MyDataset(X, y)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = MLPRegressor(input_dim=X.shape[1], hidden_dims=hidden_dims).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} - Train Loss: {np.mean(losses):.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"ÐœÐ¾Ð´ÐµÐ»ÑŒ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð° Ð² {save_path}\")\n",
    "\n",
    "\n",
    "text_embeddings = create_text_embeddings(description_mapping)\n",
    "cat_columns = ['gender', 'education', 'income', 'marital_status']\n",
    "num_columns = ['age']\n",
    "\n",
    "X, _, y, _ = prepare_features(\n",
    "    profiles, text_embeddings, num_columns, cat_columns, target, test_size=1e-10\n",
    ")\n",
    "\n",
    "train_mlp_and_save(\n",
    "    X, y,\n",
    "    hidden_dims=[512, 128],\n",
    "    n_epochs=60,\n",
    "    lr=1e-3,\n",
    "    batch_size=64,\n",
    "    save_path=\"../inference/mlp_model.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "20ab2706",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mappings = {}\n",
    "\n",
    "for col in ['gender', 'education', 'income', 'marital_status']:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(profiles[col])\n",
    "    label_mappings[col] = {cls: int(idx) for idx, cls in enumerate(le.classes_)}\n",
    "\n",
    "with open('../inference/label_mappings.json', 'w') as f:\n",
    "    json.dump(label_mappings, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d0e737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
